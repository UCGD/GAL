#!/usr/bin/perl
use strict;
use warnings;
use Getopt::Long;
use List::Util;
use List::MoreUtils;
use Statistics::Descriptive;
use Set::IntSpan::Fast;
use Template;

use FindBin;
use lib "$FindBin::RealBin/../lib";

$| = 1;

#-----------------------------------------------------------------------------
#----------------------------------- MAIN ------------------------------------
#-----------------------------------------------------------------------------

my $usage = '

Synopsis:

gff_tool --validate file.gff3
gff_tool --validate file.gvf

Description:

A script to do a lot of different operations on a GFF3 file.

Options:

All arguments given on the command line not associated with one of the
following argument flags are considered to be feature files to be
parsed and operated on.

--Input/Output Options--

  in_place|i

		  Do an in-place edit of the file. Be careful - no
		  backup copy of your original file will be created!

  out_ext|o

		  If input is coming from a file(s) and you want
		  output to be written to a file(s) of the same name
		  with an added extension, then give the extension
		  here and gff_tool will do the right thing by using
		  the same file name with the given argument as an
		  additional extenstion.

  fasta|j

		  Provide the path to a fasta file or a directory
		  containing the fasta file(s) associated with a given
		  feature file.  This argument is required by some
		  (but not all) gff_tool sunctions.  Bio::DB::Fasta
		  is used to index the fasta file.  The sequence of
		  each feature is made available to any code reference
		  given via the code argument.  See below for details
		  of code references.

  so_file

		  The location of a Sequence Ontology OBO format file.
		  The location of the file may also be given with the
		  environment variable SO_OBO.  If no file is
		  available an attempt will be made to retrieve the
		  latest version from the Sequence Ontology website.

--Include/Exclude Options--

The following filters are applied in addition to any other
manipulations just before a feature (or it\'s sequence) is printed,
and so if a feature is altered by other commands the filter will apply
to the altered copy of the feature.  All filters given are applied.

  ids|d

		  Provide a file that contains a list of IDs (or other
		  values).  The values loaded be used by the
		  include/exclude commands described below and will
		  also be made available as a hash reference ($i) to
		  the any code reference given.

  seqids

		  Provide a file that contains a list of seqids.  The
		  values loaded be used by the include/exclude
		  commands described below and will also be made
		  available as a hash reference ($si) to the any code
		  reference given.

  include|n

		  Include only those features whos IDs match the
		  values provided by the ids argument above.

  exclude|e

		  Exclude those features whos IDs match the the values
		  provided by ids argument above.

  code|c

		  A code reference that will be used by some of the
		  funcrtions below.  The code will be applied to each
		  feature as described.  All code references will have
		  available to them the following variables:

		      $i  - A hash reference of the values loaded from the
			    file given by the ids argument.
		      $si - A hash reference of the values loaded from the
			    file given by the seqids argument.
		      $f -  A hash reference for the current feature (see
			    below for more details on the structure of the
			    hash reference).
		      $t -  A hash reference for the attributes associated
			    with the current feature (see below for more
			    details on the structure of the hash reference).
		      $s -  The sequence of the current feature.  Actually
			    $s is a a code reference that will return the
			    sequence for the current feature.  This prevents
			    the code from loading the sequence for each
			    feature unless necessary.
		      $d -  A Bio::DB::Fasta object for the fasta sequences
			    given by the fasta argument described above.

  do            Apply the code reference to each feature.  The feature is not
  		printed, so this function has to handle its own printing and is
  		useful for extracting data from a GFF3 file.

  filter|t

		  Use the code reference provided with the code
		  argument described above to filter the features.
		  Print only those features that return true from the
		  given code ref.

  overlaps

		  Print only those features whose start and end coordinates
		  overlap those given as an argument to this command.
		  Coordinates are give as seqid:start-end where start
		  defaults to 1 and end defaults start or 100,000,000,000
		  if start is also not defined.

  genes

		  Keep only the gene models from a complex GFF file.

--Modify Options--

  merge|m

		  Merge takes a feature file(s) and combines the
		  features.  If gff_tool encounters a second feature
		  that shares an ID with a previously encountered
		  feature then both of those features are passed to
		  the given code reference and the feature that is
		  returned by the code reference will be saved.  If no
		  code reference is given, then the first feature
		  encountered will be saved and a warning issued.

  blend|b

		  Blend takes two or more feature files and uniquely blends
		  the attributes for features that share the same ID.
		  If two features have the same ID, but conflict in
		  ways other than the attributes (i.e. seqid, source,
		  type, start, end, strand, phase values) then blend
		  will use any code reference provided to the code
		  argument to resolve which feature to save as
		  described above for the merge command.  If no code
		  reference is available then blend will keep the
		  values from the first feature encountered, then
		  blend the attributes and issue a warning.

  l_blend

		  The l_blend function takes two or more feature files
		  and uniquely blends the attributes for features that
		  share the same locus and type (i.e. if seqid start
		  end strand and type are identical the records are
		  blended).  If two features have the same locus, but
		  conflict in ways other than the attributes
		  (i.e. seqid, source, type, start, end, strand, phase
		  values) then blend will use any code reference
		  provided to the code argument to resolve which
		  feature to save as described above for the merge
		  command.  If no code reference is available then
		  blend will keep the values from the first feature
		  encountered, then blend the attributes and issue a
		  warning.

  sort|s

		  Sort the feature file using the code reference given
		  by the code argument described above.  If no code
		  argument is given the sort will sort lexigraphically
		  on seqid and numerically on start and reverse
		  numerically on end.(Not yet implimented)

  alter|a

		  Apply the code reference given by the code argument
		  described above to each feature.  This is identical
		  to the filter command described above, but any
		  alteration made to the feature by the code
		  reference is kept in printing.

  hash_ag

		  The hash_ag function aggregates all the features in
		  a file to a hash based on user specified code.  It
		  then iterates over each key in that hash and runs
		  another block of user specified code on the value(s)
		  that were stashed in that hash value. This could,
		  for examples, be used to stash all data into a hash
		  keyed off the feature type and then calculate and
		  print the averages score for each feature type.  The
		  hash_ag argument takes a code reference.  A second
		  code reference passed to the code argument is also
		  required.  The function uses the code reference
		  supplied by the code argument described above to
		  create a hash (%h).  This may be done, for example,
		  by pushing all features onto the values of %h keyed
		  by seqid or type.  After all features have been been
		  iterated over (and possibly stored) this way,
		  another loop is run over each key of %h and the code
		  reference provided to the hash_ag argument is run
		  for each iteration through that loop.  The variables
		  made available within this loop are as follows:

		      %h - The hash created as described above.
		      $k - The current key.
		      $v - The current value.

		  See the Examples section below.

  map_seqids

		  Map the seqid values forward using the given mapping
		  file.  The argument to this option is a
		  tab-delimited text file with two columns, the first
		  column being the current seqid as found in the GFF3
		  file, and the second value being associated the new
		  seqid that will replace the old one.

  map_feature_ids

		  Map the feature IDs values forward using the given
		  mapping file.  The argument to this option is a
		  tab-delimited text file with two columns, the first
		  column is the current feature ID as found in the
		  GFF3 ID attribute and the second value is the new
		  feature ID that will replace the old one.  This will
		  map the IDs in both ID and Parent attributes.

--Reporting Options--

  template

		  Pass a Template Toolkit
		  (http://www.template-toolkit.org/) formatted
		  template and gff_tool will pass the variant data to
		  the templating engine.  See the lib/GAL/templates
		  directory for example templates.

  validate|v

		  The validate command provides simple validation for
		  GFF3 and GVF files.  Constraints on values and
		  attributes are checked as described in the GFF3 and
		  GVF specification.  If a ##gvf-version pragma is
		  encountered then GVF constraints will be applied in
		  addition to GFF3 constraints, otherwise the file
		  will be validated as GFF3.  Values that are
		  constrained by the GVF or GFF3 specification to be
		  SO terms are checked but SO relationships are not
		  currently enforced.  A SO.obo file can be passed as
		  an argument to the validate argument and this file
		  will be used to validate the SO terms used in the
		  file.  If no SO file is given, gff_tools will
		  attempt to access the the current SO file from the
		  SO website.  If no SO file is available by any of
		  the above methods, then no validation of SO terms
		  will be done.  An error report will be printed to
		  STDOUT.

  stats|u

		  Return simple summary statistics for the given file.
		  (Not yet implimented)

--Add/Extract Options--

  print           Just print the features - applying any include/exclude
		  along the way.

  print_data      Print a subset of the data for each feature in GFF file.
		  This option takes a comma separated list of
		  feilds/attributes and prints just those values for
		  each feature.  Values to this option include:
		      seqid, source, type, start, end, strand, phase,
		      attributes.

		  In addition to these there are a few keywords that
		  will print calculated values:
		      locus (seqid:start-end), length (start - end + 1),
		      genotype (locus:nt,nt)

		  Finally, any attribute can be printed by passing its
		  key, for example:
		      ID, Name, Reference_seq, etc.

		  If you have an attribute that shares one of the
		  reserved names above (e.g. an attribute named
		  length) simply prepend a + to the attribute name and
		  it will be recognized as an attribute.

  sequence|p      Print a fasta sequence for each feature instead of
		  the feature. Requires the fasta argument (Not yet
		  implimented)

  splice_sequence Print the mature fasta sequence for spliced
		  features (exons, CDS)

  features|x      Print only feature lines, removing all meta-data,
		  comments, empty lines and fasta from a GFF file.

  fasta_only|r    Print only the fasta sequences from the ##FASTA
		  section from a GFF3 file.

  fasta_no|R      Remove the ##FASTA section from a GFF3 file.

  fasta_add|q     Add the given fasta file to the GFF3 output in a ##FASTA
		  section.

  meta_only|y     Print only the meta-data lines (pragmas, comments and
		  empty lines) from a GFF file.

  meta_no|Y       Do not print the meta-data lines (pragmas, comments and
		  empty lines) from a GFF file.

  meta_add|z      Add the meta-data contained in the given file to the
		  begining of a GFF file.

  pragmas|w       Interactively add GFF3/GVF pragmas to the top of the
		  file.  Use GFF3 or GVF (case insensitive) as an
		  argument to signify which pragma style to
		  create. (Not yet implimented)

  add_ID|v        Add ID attributes where they dont already
		  exist. (Not yet implimented)


--Set Operations (Coordinate matching) --

		  All coordinate matching set operations are based on
		  seqid:start:end unless the set_seq option is set in
		  which case it becomes
		  seqid:start:end:Reference_seq:Variant_seq.  The
		  Reference_seq is removed from the Variant_seq list.
		  These set operations are useful, for example, for
		  operating on sets of SNVs from a family or
		  population.

  union           The union of all files.  The members that are
		  present in any file.

  intersection    The intersection of all files.  The members that
		  are present in all files.

  lcomplement     The left releative complement of the files.  The
		  members found exclusively in the first file but not
		  in any subsequent files.

  sdifference     The symetric difference of the files.  The members
		  found in exactly one file.  Note that the symetric
		  difference should technically give you the members
		  that are present in an odd number of files, but on
		  sets of more than two files that is probably never
		  what you want in this application, so here we give
		  you only the memebers that are present in exactly
		  one file


--Set Operations (Interval Overlap) --

		  All interval overlap set operations are based on
		  intersecting the genomic intervals occupied by a
		  feature and creating new features based on the set
		  operation.  These operations are useful, for
		  example, in finding the similar or dissimilar
		  regions between two sets of exons.

  i_union         Create a new set of features that is the union of
		  regions between all supplied features.

  i_intersection  Create a new set of features that contain only the
		  regions of intersection between all supplied features.

  i_lcomplement   Create a new set of features that contain the
		  regions found only in the first set of features.

  i_sdifference   Create a new set of features that contain the regions
		  that are found in one and only one file. - Not yet
		  implimented.


--GVF Options--

  titv           Calculate transition/transversion ratio.
  gvf_stats      Simple SNV stats on a GVF file.
  effect_stats   Category counts for Variant_effect terms.
  gvf_sets       Calculate counts the pairwise intersection and complement
		 for all files and the symetric difference for each
		 file. (Not yet implimented)
  fix_gvf        Fix up some common errors in GVF files.  Currently it
		 changes Genotype=(hetero|homo)zygous attributes to
		 Zygosity=(hetero|homo)zygous uniques the Variant_seq
		 values and removes homozygous reference variants.

  add_ref_seq    Add the value for the Reference_seq attribute.  This
		 option requires a numerical value which indicates the
		 length of sequence to be represented.  Any sequence
		 longer than the given value will be represented by ~#
		 where # will be the length of the sequence.  If a
		 value of 0 is provided then all sequences will be
		 reporesented full length.  The add_ref_seq function
		 requires that a FASTA formatted sequence file be
		 passed to the --fasta argument.  This function will
		 read seqeunce from the fasta file for the range
		 specified by start and end (columns 4 and 5) and will
		 add or update the Reference_seq attribute to contain
		 that sequence, representing longer sequences with ~
		 as described above.

  gvf2vcf        Convert single GVF files to VCF format.  This is a
		 minimal converter that will convert SNVs and simple
		 indels with minimal support for extended VCF options.
		 Only variant lines are printed, no meta-data.

Code References:

All code refs have available to them the current feature as a hash
reference ($f), the attributes of the current feature as a separate
hash reference ($t), any list of values loaded with the ids argument
($i), any values loded with the seqids argument ($si), the sequence of
the current feature ($s) and the current Bio::DB::Fasta object ($d) if
the fasta argument was given.  Changes made by code references can
change any of the values in the variables mentioned above, but those
changes will be discarded before the feature is printed except when
the alter argument is given.  The attributes located in $t are the
same as the ones located in $f->{attributes} but when the alter
command is in effect the values in $t will clobber the
$f->{attributes} before the feature is printed.

The structure of hash references discussed above are:

$f = {feature_id => $feature_id, # Same as the value of the ID attribute
      seqid      => $seqid,
      source     => $source,
      type       => $type,
      start      => $start,
      end        => $end,
      score      => $score,
      strand     => $strand,
      phase      => $phase,
      attributes => $t,
     }

$t = {tag1 => [value1],
      tag2 => [value1, value2],
     }

Examples:

# The --hash_ag code pushes each feature onto a hash keyed by type
# The --code code sorts the stashed feautres by length and shifts off
# longest one which is returned and printed.
gff_tool --hash_ag "push @{$h{$f->{type}}}, $f"          \
	 --code "my @x = sort {($a->{end} - $a->{start}) \
	   <=> ($b->{end} - $b->{start})} @$v;shift @x"  \
	   features.gff3

';

my ($help, $in_place, $out_ext, $FASTA_FILE, $SO_FILE, $IDS_FILE,
    $SEQIDS_FILE, $include, $exclude, $code, $do_stuff, $filter,
    $overlaps, $genes, $merge, $blend, $l_blend, $sort, $alter,
    $hash_ag, $map_seqids, $map_feature_ids, $template, $validate,
    $stats, $print_gff, $print_data, $sequence, $splice_sequence,
    $fasta_only, $fasta_no, $fasta_add, $meta_only, $meta_no,
    $meta_add, $add_ID, $pragmas, $features, $union, $intersection,
    $lcomplement, $sdifference, $i_union, $i_intersection,
    $i_lcomplement, $i_sdifference, $titv, $gvf_stats, $effect_stats,
    $gvf_sets, $fix_gvf, $add_ref_seq, $gvf2vcf);

my $opt_success = GetOptions('help|h'		 => \$help,
			     'in_place|i'	 => \$in_place,
			     'out_ext|o=s'	 => \$out_ext,
			     'fasta|j=s'	 => \$FASTA_FILE,
			     'so_file=s'	 => \$SO_FILE,
			     'ids|d=s'		 => \$IDS_FILE,
			     'seqids|d=s'	 => \$SEQIDS_FILE,
			     'include|n'	 => \$include,
			     'exclude|e'	 => \$exclude,
			     'code|c=s'		 => \$code,
                             'do'                => \$do_stuff,
			     'filter|t'          => \$filter,
			     'overlaps=s'	 => \$overlaps,
			     'genes'		 => \$genes,
			     'merge|m'		 => \$merge,
			     'blend|b'		 => \$blend,
			     'l_blend'		 => \$l_blend,
			     'sort|s'		 => \$sort,
			     'alter|a'		 => \$alter,
			     'hash_ag=s'	 => \$hash_ag,
			     'map_seqids=s'	 => \$map_seqids,
			     'map_feature_ids=s' => \$map_feature_ids,
			     'template=s'        => \$template,
			     'validate|v'	 => \$validate,
			     'stats|u'		 => \$stats,
			     'sequence|p'	 => \$sequence,
			     'splice_sequence'	 => \$splice_sequence,
			     'print'		 => \$print_gff,
			     'print_data=s'      => \$print_data,
			     'features|x'	 => \$features,
			     'fasta_only|r'	 => \$fasta_only,
			     'fasta_no|R'	 => \$fasta_no,
			     'fasta_add|q=s'	 => \$fasta_add,
			     'meta_only|y'	 => \$meta_only,
			     'meta_no|Y'	 => \$meta_no,
			     'meta_add|z=s'	 => \$meta_add,
			     'pragmas|w=s'	 => \$pragmas,
			     'add_ID|v'		 => \$add_ID,
			     'union'		 => \$union,
			     'intersection'	 => \$intersection,
			     'lcomplement'	 => \$lcomplement,
			     'sdifference'	 => \$sdifference,
			     'i_union'		 => \$i_union,
			     'i_intersection'	 => \$i_intersection,
			     'i_lcomplement'	 => \$i_lcomplement,
			     'i_sdifference'	 => \$i_sdifference,
			     'titv'		 => \$titv,
			     'gvf_stats'	 => \$gvf_stats,
			     'effect_stats'	 => \$effect_stats,
			     'gvf_sets'		 => \$gvf_sets,
			     'fix_gvf'		 => \$fix_gvf,
			     'add_ref_seq'       => \$add_ref_seq,
			     'gvf2vcf'           => \$gvf2vcf,
			    );

if (! $opt_success) {
    print STDERR join ' : ', ('FATAL',
			      'command_line_parse_error',
			      'Use gff_tool --help to see correct usage');
}

if ($help || !@ARGV) {
 print $usage;
 exit(0);
}

die "FATAL : unreadable_file : $FASTA_FILE\n" if ($FASTA_FILE && ! -r $FASTA_FILE);
die "FATAL : unreadable_file : $SO_FILE\n"    if ($SO_FILE    && ! -r $SO_FILE);

my @files = @ARGV;
die "$usage\n\nFATAL : no_file_given : Must give one or more feature files\n\n" unless (scalar @files || ! -t STDIN);
for my $file (@files) {
 next if $file eq '-';
 die "FATAL : unable_to_open_file : $file\n" if ! -r $file;
}

my $FASTA_DB = parse_fasta($FASTA_FILE) if $FASTA_FILE;
my $IDS      = parse_ids($IDS_FILE)     if $IDS_FILE;
my $SEQIDS   = parse_ids($SEQIDS_FILE)  if $SEQIDS_FILE;

# Move the filter code to the passes_filters sub
filter(\@files, $code)			    if $filter;
overlaps(\@files, $overlaps)		    if $overlaps;
do_stuff(\@files, $code)                    if $do_stuff;
genes(\@files)				    if $genes;
merge(\@files)				    if $merge;
blend_gff(\@files)			    if $blend;
l_blend_gff(\@files)			    if $l_blend;
sort_gff(\@files)			    if $sort;
alter_gff(\@files, $code)		    if $alter;
hash_ag(\@files, $hash_ag, $code)	    if $hash_ag;
map_seqids(\@files, $map_seqids)	    if $map_seqids;
map_feature_ids(\@files, $map_feature_ids)  if $map_feature_ids;
template(\@files, $template)                if $template;
validate(\@files)			    if $validate;
stats(\@files)				    if $stats;
sequence(\@files)			    if $sequence;
splice_sequence(\@files)		    if $splice_sequence;
features(\@files)			    if $features;
fasta_only(\@files)			    if $fasta_only;
fasta_add(\@files, $fasta_add)		    if $fasta_add;
meta_only(\@files)			    if $meta_only;
#meta_no(\@files)			    if $meta_no;
meta_add(\@files)			    if $meta_add;
add_ID(\@files)				    if $add_ID;
print_gff(\@files)			    if $print_gff;
print_data(\@files, $print_data)            if $print_data;
union(\@files)				    if $union;
intersection(\@files)			    if $intersection;
lcomplement(\@files)			    if $lcomplement;
sdifference(\@files)			    if $sdifference;
i_union(\@files)			    if $i_union;
i_intersection(\@files)			    if $i_intersection;
i_lcomplement(\@files)			    if $i_lcomplement;
i_sdifference(\@files)			    if $i_sdifference;
calc_titv(\@files)			    if $titv;
gvf_stats(\@files)			    if $gvf_stats;
effect_stats(\@files)			    if $effect_stats;
gvf_sets(\@files)			    if $gvf_sets;
fix_gvf(\@files)                            if $fix_gvf;
add_ref_seq(\@files, $add_ref_seq)          if defined $add_ref_seq;
gvf2vcf(\@files)                            if $gvf2vcf;
fasta_no(\@files)			    if $fasta_no;

#pragma($pragma)			  if $pragma;

#-----------------------------------------------------------------------------
#-------------------------------- SUBROUTINES --------------------------------
#-----------------------------------------------------------------------------

#-----------------------------------------------------------------------------
#   do_stuff    Apply the code reference to each feature.  The feature is not
#   		printed, but the return value from the code reference
#   		is printed, so this function is useful for extracting
#   		data from a GFF3 file.
#-----------------------------------------------------------------------------

sub do_stuff {

    my ($files, $code) = @_;

    for my $file (@files) {
	my $IN  = fh_in($file);
	my $OUT = fh_out($file);
	while (my $f_original = next_feature_hash($IN, $OUT)) {

	    my $f  = $f_original;
	    my $t  = $f->{attributes};
	    my $i  = $IDS;
	    my $si = $SEQIDS;
	    my $d  = $FASTA_DB;

	    my $return_value = eval $code;
	    die "FATAL : fatal_error_in_code_ref : $code\n$@\n" if $@;
	    next unless $return_value;
	    print "$return_value\n"
	}
    }
    exit;
}


#-----------------------------------------------------------------------------
#  filter|t        Use the code reference provided with the code
#		  argument described above to filter the features.
#		  Print only those features that return true from the
#		  given code ref.
#  Examples:
#  gff_tool --filter --code 'return 1 if $f->{score} < 100'
#  gff_tool --filter --code 'return 1 unless $t->{Genotype} =~ /homozygous/i'
#-----------------------------------------------------------------------------

sub filter {

    my ($files, $code) = @_;

    for my $file (@files) {
	my $IN  = fh_in($file);
	my $OUT = fh_out($file);
	while (my $f_original = next_feature_hash($IN, $OUT)) {

	    my $f  = $f_original;
	    my $t  = $f->{attributes};
	    my $i  = $IDS;
	    my $si = $SEQIDS;
	    my $d  = $FASTA_DB;

	    my $return_value = eval $code;
	    die "FATAL : fatal_error_in_code_ref : $code\n$@\n" if $@;
	    next unless $return_value;

	    print $OUT to_gff3($f_original);
	    print '';
	}
    }
    exit;
}

#-----------------------------------------------------------------------------
#  overlaps        Print only those features whose start and end coordinates
#                  overlap those given as an argument to this command.
#                  Coordinates are give as seqid:start-end where start
#                  defaults to 1 and end defaults start or 100,000,000,000
#                  if start was also not defined.
#
#  Examples:
#  gff_tool --overlaps chr1:5000-1000
#  gff_tool --overlaps chr1:5000       # same as chr1:5000-5000
#  gff_tool --overlaps chr1            # same as chr1:1-100,000,000,000
#-----------------------------------------------------------------------------

sub overlaps {

    my ($files, $locus) = @_;

    my ($l_seqid, $l_start, $l_end) = split /[:-]/, $locus;
    if (! defined $l_start) {
	$l_start = 1;
	$l_end   = 100000000000;
    }
    $l_end ||= $l_start;

    for my $file (@files) {
	my $IN  = fh_in($file);
	my $OUT = fh_out($file);
	while (my $f = next_feature_hash($IN, $OUT)) {

	    next if $l_seqid ne $f->{seqid};
	    next unless $l_start <= $f->{end};
	    next unless $l_end   >= $f->{start};

	    print $OUT to_gff3($f);
	}
    }
    exit;
}

#-----------------------------------------------------------------------------
#  genes        Keep only the features commonly associated with gene models
#               from a complex GFF file. (gene mRNA transcript exon CDS
#               start_codon stop_codon three_prime_UTR five_prime_UTR).
#
#  Examples:
#  gff_tool --genes file.gff
#
#-----------------------------------------------------------------------------

sub genes {

  my ($files, $code) = @_;

  my %accept = (
      gene                =>  1,
      mRNA                =>  1,
      ncRNA               =>  1,
      tRNA                =>  1,
      piRNA               =>  1,
      rRNA                =>  1,
      rasiRNA             =>  1,
      scRNA               =>  1,
      siRNA               =>  1,
      snRNA               =>  1,
      snoRNA              =>  1,
      stRNA               =>  1,
      tasiRNA             =>  1,
      transcript          =>  1,
      primary_transcript  =>  1,
      exon                =>  1,
      CDS                 =>  1,
      start_codon         =>  1,
      stop_codon          =>  1,
      three_prime_UTR     =>  1,
      five_prime_UTR      =>  1,
      );

  # Make filehandles autoflush
  $|++;

  for my $file (@files) {
    my $IN  = fh_in($file);
    my $OUT = fh_out($file);
    print_pragmas($IN, $OUT);
    while (my $f = next_feature_hash($IN, $OUT)) {
      next unless defined $accept{$f->{type}};
      print $OUT to_gff3($f);
    }
  }
  exit;
}

#-----------------------------------------------------------------------------
#  merge|m        Merge takes a feature file(s) and combines the
#		  features.  If gff_tool encounters a second feature
#		  that shares an ID with a previously encountered
#		  feature then both of those features are passed to
#		  the given code reference and the feature that is
#		  returned by the code reference will be saved.  If no
#		  code reference is given, then the first feature
#		  encountered will be saved and a warning issued.
#  Examples:
#
#  Merge two gff files keeping the feature with the greater Variant_freq
#  if two features have the same ID.
#
#  gff_tool --merge --code 'return sort {$a->{Variant_freq} <=> $b->{Variant_freq} ($af, $bf)}'
#-----------------------------------------------------------------------------

sub merge_gff {

    my $files = shift;

    die "FATAL : feature_not_implimented : gff_tool --merge\n";
    exit;
}

#-----------------------------------------------------------------------------
#  blend|b
#
#		  Blend takes a feature file(s) and uniquely blends
#		  the attributes for features that share the same ID.
#		  If two features have the same ID, but conflict in
#		  ways other than the attributes (i.e. seqid, source,
#		  type, start, end, strand, phase values) then blend
#		  will use any code reference provided to the code
#		  argument to resolve which feature to save as
#		  described above for the merge command.  If no code
#		  reference is available then blend will keep the
#		  values from the first feature encountered, then
#		  blend the attributes and issue a warning.
#
#  Examples:
#
#  Blend two GFF files blending the attributes of two features that
#  share the same ID.
#
#  gff_tool --blend --code 'return $bf' file1.gff file2.gff
#-----------------------------------------------------------------------------

sub blend_gff {

    my $files = shift;

    send_message ('WARN',
		  'blend_gff_not_thouroughly_tested',
		  'blend has not been thouroughly tested.  Please help',
		  'us improve gff_tool by carefully evaluating your',
		  'output and contacting us if you find errors.',
		  );

    my %features;
    for my $file (@files) {
	my $IN  = fh_in($file);
	my $count = 0;
	while (my $feature = next_feature_hash($IN)) {
	    my $feature_id = $feature->{feature_id};
	    $feature->{count} = $count++;
	    push @{$features{$feature_id}}, $feature;
	}
    }

    my $OUT = fh_out();

    for my $feature_id (sort {$features{$a}[0]{count} <=>
			      $features{$b}[0]{count}} keys %features) {
	my @feature_group = @{$features{$feature_id}};
	my %blend_attributes;
	my %base_feature;
	my %seen_atts;
	if (scalar @feature_group == 1) {
	    %base_feature = %{$feature_group[0]};
	}
	else {
	    for my $feature (@feature_group) {
		my $attributes = $feature->{attributes};
		if (! %base_feature) {
		    @base_feature{qw(feature_id seqid source type start end score strand phase)} =
			@{$feature}{qw(feature_id seqid source type start end score strand phase)};
		}
		for my $tag (keys %{$attributes}) {
		    my @values = @{$attributes->{$tag}};

		    ##########################################################
		    ##########################################################
		    # Temprorary Hack!!! 5/3/10
		    @values = grep {/:\d+$/} @values if $tag eq 'Variant_seq';
		    ##########################################################
		    ##########################################################

		    my @new_values = grep {! $seen_atts{$tag}{$_}++} @values;
		    push @{$blend_attributes{$tag}}, @new_values;
		}
	    }
	    $base_feature{attributes} = \%blend_attributes;
	}
	print $OUT to_gff3(\%base_feature);
    }
    exit;
}

#-----------------------------------------------------------------------------
#  l_blend
#
#		  The l_blend function takes two or more feature files
#		  and uniquely blends the attributes for features that
#		  share the same locus and type (i.e. if seqid start
#		  end strand and type are identical the records are
#		  blended).  If two features have the same locus, but
#		  conflict in ways other than the attributes
#		  (i.e. seqid, source, type, start, end, strand, phase
#		  values) then blend will use any code reference
#		  provided to the code argument to resolve which
#		  feature to save as described above for the merge
#		  command.  If no code reference is available then
#		  blend will keep the values from the first feature
#		  encountered, then blend the attributes and issue a
#		  warning.
#
#  Examples:
#
#  Blend two GFF files blending the attributes of two features that
#  share the same locus.
#
#  gff_tool --l_blend file1.gff file2.gff
#-----------------------------------------------------------------------------

sub l_blend_gff {

    my $files = shift;

    send_message ('WARN',
		  'l_blend_gff_not_thouroughly_tested',
		  'blend has not been thouroughly tested.  Please help',
		  'us improve gff_tool by carefully evaluating your',
		  'output and contacting us if you find errors.  Thanks',
		  );

    my %features;
    for my $file (@files) {
	my $IN  = fh_in($file);
	my $count = 0;
	while (my $feature = next_feature_hash($IN)) {
	    my $locus = join ':', @{$feature}{qw(seqid start end strand type)};
	    $feature->{count} = $count++;
	    push @{$features{$locus}}, $feature;
	}
    }

    my $OUT = fh_out();

    for my $locus (sort {$features{$a}[0]{count} <=>
			      $features{$b}[0]{count}} keys %features) {
	my @feature_group = @{$features{$locus}};
	my %blend_attributes;
	my %base_feature;
	my %seen_atts;
	if (scalar @feature_group == 1) {
	    %base_feature = %{$feature_group[0]};
	}
	else {
	    for my $feature (@feature_group) {
		my $attributes = $feature->{attributes};
		if (! %base_feature) {
		    @base_feature{qw(feature_id seqid source type start end score strand phase)} =
			@{$feature}{qw(feature_id seqid source type start end score strand phase)};
		}
		for my $tag (keys %{$attributes}) {
		    my @values = @{$attributes->{$tag}};

		    my @new_values = grep {! $seen_atts{$tag}{$_}++} @values;
		    push @{$blend_attributes{$tag}}, @new_values;
		}
	    }
	    $base_feature{attributes} = \%blend_attributes;
	}
	print $OUT to_gff3(\%base_feature);
    }
    exit;
}

#-----------------------------------------------------------------------------
#  sort|s         Sort the feature file using the code reference given
#		  by the code argument described above.  (Not yet
#		  implimented)
#
#-----------------------------------------------------------------------------

sub sort_gff {

    my ($file, $code) = @_;

    die "FATAL : feature_not_implimented : gff_tool --sort\n";

    $code ||= '{$a->{seqid}';

    my $IN = fh_in($file);
    my $OUT = fh_out($file);
    while (my $f = next_feature_hash($IN, $OUT)) {

	my $t = $f->{attributes};
	my $i = $IDS;
	my $si = $SEQIDS;
	my $d = $FASTA_DB;

	print $OUT to_gff3($f);
    }
    exit;
}

#-----------------------------------------------------------------------------
#  alter|a        Apply the code reference given by the code argument
#		  described above to each feature.  This is identical
#		  to the filter command described above, but any
#		  alteration made the the feature by the code
#		  reference is kept.
#
#-----------------------------------------------------------------------------

sub alter_gff {

    my ($files, $code) = @_;

    for my $file (@files) {
	my $IN = fh_in($file);
	my $OUT = fh_out($file);
	while (my $f = next_feature_hash($IN, $OUT)) {

	    my $t = $f->{attributes};
	    my $i = $IDS;
	    my $si = $SEQIDS;
	    my $d = $FASTA_DB;

	    my $return_value = eval $code;
	    die "FATAL : fatal_error_in_code_ref : $code\n$@\n" if $@;

	    $f->{attributes} = $t;

	    print $OUT to_gff3($f);
	}
    }
    exit;
}

#-----------------------------------------------------------------------------
#  hash_ag|h
#
#		  The hash_ag argument takes a code reference.  A
#		  second code reference passed to the code argument is
#		  also required.  The function uses the code reference
#		  supplied by the code argument described above to
#		  create a hash (%h).  This may be done, for example,
#		  by pushing all features onto the values of %h keyed
#		  by seqid or type.  After all features have been been
#		  iterated over (and possibly stored) this way,
#		  another loop is run over each key of %h and the code
#		  reference provided to the hash_ag argument is run for each
#		  iteration through that loop.  The variables made
#		  available within this loop are as follows:
#
#		      %h - The hash created as described above.
#		      $k - The current key.
#		      $v - The current value.
#
#		  See the Examples section below.
#-----------------------------------------------------------------------------

sub hash_ag {

    my ($files, $ag_code, $code) = @_;

    my %h;
    for my $file (@{$files}) {
	my $IN = fh_in($file);
	while (my $f = next_feature_hash($IN)) {

	    my $t = $f->{attributes};
	    my $i = $IDS;
	    my $si = $SEQIDS;
	    my $d = $FASTA_DB;

	    my $return_value = eval $ag_code;
	    die "FATAL : fatal_error_in_code_ref : $ag_code\n$@\n" if $@;
	}
    }

    my $OUT = fh_out();
    for my $k (keys %h) {

	my $v = $h{$k};

	my @f = eval $code;
	die "FATAL : fatal_error_in_code_ref : $code\n$@\n" if $@;
	next unless @f;

	print $OUT to_gff3(\@f);
    }
    exit;
}

#-----------------------------------------------------------------------------
#  map_seqids
#
#                  Map the seqid values forward using the given mapping
#                  file.  The argument to this option is a
#                  tab-delimited text file with two columns, the first
#                  column being the current seqid as found in the GFF3
#                  file, and the second value being associated the new
#                  seqid that will replace the old one.
#
#-----------------------------------------------------------------------------

sub map_seqids {

    my ($files, $map_file) = @_;

    die "FATAL : file_does_not_exist : $map_file\n" unless -e $map_file;
    die "FATAL : file_not_readable : $map_file\n"   unless -r $map_file;

    open(my $MAP, '<', $map_file) or
	die "FATAL : cant_open_file_for_reading : $map_file\n";

    my %map;
  LINE:
    while (my $line = <$MAP>) {
	next LINE if $line =~ /^\#/;
	chomp $line;
	if ($line =~ /^\s/) {
	    warn("WARN : skipping_line_in_mapping_file : " .
		 "(Line begins with whitespace) '$line'\n");
	    next LINE;
	}
	if ($line !~ /\t/) {
	    warn("WARN : skipping_line_in_mapping_file : " .
		 "(Line has no tab) '$line'\n");
	    next LINE;
	}
	my ($old, $new) = split /\t/, $line;
	if (! defined $old) {
	    warn("WARN : skipping_line_in_mapping_file : " .
		 "(Line has no seqids) '$line'\n");
	    next LINE;
	}
	if (! defined $new) {
	    warn("WARN : skipping_line_in_mapping_file : " .
		 "(Line has no new seqid) '$line'\n");
	    next LINE;
	}
	if (exists $map{$old}) {
	    my $current_map = $map{$old};
	    warn("WARN : overwriting_existing_seqid_map_value : " .
		 "($old => $current_map) is being replaced by ($old => $new)\n");
	}
	$map{$old} = $new;
    }

    
    # Make the file handles autoflush.
    $|++;

    for my $file (@{$files}) {
	my $OUT = fh_out();
	my $IN  = fh_in($file);

	# Map pragmas
	my @pragmas = read_pragmas($IN);
	for my $pragma_text (@pragmas) {
	    if ($pragma_text =~ /^\#\#sequence-region/) {
		my ($pragma, $space1, $seqid, $space2, $start,
		    $space3, $end) = split /(\s+)/, $pragma_text;
		my $new_seqid;
		if (exists $map{$seqid}) {
		    $new_seqid = $map{$seqid};
		}
		else {
		    warn("WARN : no_value_in_seqid_map : $seqid\n");
		    $new_seqid = $seqid;
		}
		$pragma_text = join '', ($pragma, $space1, $new_seqid,
					 $space2, $start, $space3, $end);
	    }
	    print $OUT "$pragma_text\n";
	}

	# Map features
	while (my $f = next_feature_hash($IN, $OUT)) {
	    my $seqid = $f->{seqid};
	    my $new_seqid;
	    if (exists $map{$seqid}) {
		$new_seqid = $map{$seqid};
	    }
	    else {
		warn("WARN : no_value_in_seqid_map : $seqid\n");
		$new_seqid = $seqid;
	    }
	    $f->{seqid} = $new_seqid;
	    print $OUT to_gff3($f);
	}
    }
}

#-----------------------------------------------------------------------------
#  map_feature_ids
#
#		  Map the feature IDs values forward using the given
#		  mapping file.  The argument to this option is a
#		  tab-delimited text file with two columns, the first
#		  column being the current feature ID as found in the
#		  GFF3 ID attribute file, and the second value being
#		  associated the new feature ID that will replace the
#		  old one.  This will map the IDs in both ID and
#		  parent attributes.
#-----------------------------------------------------------------------------

sub map_feature_ids {

  my ($files, $map_file) = @_;

  die "FATAL : file_does_not_exist : $map_file\n" unless -e $map_file;
  die "FATAL : file_not_readable : $map_file\n"   unless -r $map_file;

  open(my $MAP, '<', $map_file) or
    die "FATAL : cant_open_file_for_reading : $map_file\n";

  my %map;
 LINE:
  while (my $line = <$MAP>) {
    next LINE if $line =~ /^\#/;
    chomp $line;
    if ($line =~ /^\s/) {
      warn("WARN : skipping_line_in_mapping_file : " .
	   "(Line begins with whitespace) '$line'\n");
      next LINE;
    }
    if ($line !~ /\t/) {
      warn("WARN : skipping_line_in_mapping_file : " .
	   "(Line has no tab) '$line'\n");
      next LINE;
    }
    my ($old, $new) = split /\t/, $line;
    if (! defined $old) {
      warn("WARN : skipping_line_in_mapping_file : " .
	   "(Line has no feature_id) '$line'\n");
      next LINE;
    }
    if (! defined $new) {
      warn("WARN : skipping_line_in_mapping_file : " .
	   "(Line has no new feature_id) '$line'\n");
      next LINE;
    }
    if (exists $map{$old}) {
      my $current_map = $map{$old};
      warn("WARN : overwriting_existing_feature_id_map_value : " .
	   "($old => $current_map) is being replaced by ($old => $new)\n");
    }
    $map{$old} = $new;
  }

  for my $file (@{$files}) {
    my $OUT = fh_out();
    my $IN = fh_in($file);

    # Map features
    while (my $f = next_feature_hash($IN, $OUT)) {
      my $attributes = $f->{attributes};
      my $feature_id = $attributes->{ID}[0];
      my $new_feature_id = $feature_id;
      if (exists $map{$feature_id}) {
	$new_feature_id = $map{$feature_id};
	$f->{feature_id} = $new_feature_id;
	$attributes->{ID} = [$new_feature_id];
      }

      my $parents = $attributes->{Parent} if exists $attributes->{Parent};
      for my $parent (@{$parents}) {
	if (exists $map{$parent}) {
	  $parent = $map{$parent};
	}
      }
      print $OUT to_gff3($f);
    }
  }
}

#-----------------------------------------------------------------------------
#  validate|v
#
#		  The validate command provides simple validation for
#		  GFF3 and GVF files.  Constraints on values and
#		  attributes are checked as described in the GFF3 and
#		  GVF specification.  If a ##gvf-version pragma is
#		  encountered then GVF constraints will be applied in
#		  addition to GFF3 constraints, otherwise the file
#		  will be validated as GFF3.  Values that are
#		  constrained by the GVF or GFF3 specification to be
#		  SO terms are checked but not SO relationships are
#		  not currently enforced.  A SO.obo file can be passed
#		  as an argument to the validate argument and this
#		  file will be used to validate the SO terms used in
#		  the file.  If no SO file is given, gff_tools will
#		  attempt to access the the current SO file from the
#		  SO website.  If no SO file is available by any of
#		  the above methods, then no validation of SO terms
#		  will be done.  An error report will be printed to
#		  STDOUT.
#-----------------------------------------------------------------------------

sub validate {

  my $files = shift;

  my %valid_so_terms;
  my ($so_data) = parse_so_file();
  # map {$valid_so_terms{$_}++;$valid_so_terms{$so_data->{map}{$_}}++}
  #     keys %{$so_data->{terms}};

    for my $file (@{$files}) {
	warn "Validating: $file\n";
	open(my $IN, '<', $file) or
	    die "FATAL : cant_open_file_for_reading : $file\n";

	my $line_count;
	my %pragmas;
	my %errors;
	# my %valid_so_terms;
	my $gff_version;
	my $gvf_version;
	my %feature_ids;
	my %parents;

	my @stack;
	my $line = <$IN>;
	my ($format_type, $version) = split /\t+/, $line;
	if ($format_type !~ /g[vf]f-version/) {
	    my $error_code = 'missing_required_gff-version_or_gvf-version_pragma';
	    push @{$errors{$error_code}}, [1, $line];
	    warn "WARNING : $error_code : Assuming this file is \#\#gff-version 3 for validation.\n";
	    push @stack, ("\#\#gff-version 3", $line);
	    $line_count--;
	}

      LINE:
	while ($line = shift @stack || <$IN>) {
	    chomp $line;
	    $line_count++;
	    next LINE if $line =~ /^\s*$/;
	    next LINE if $line =~ /^\#[^\#]/;
	    # Features
	    if ($line !~ /^\#/) {
		if ($line !~ /\t/) {
		    my $error_code = 'invalid_feature_line_not_tab_delimited';
		    push @{$errors{$error_code}}, [$line_count, $line];
		    warn "WARNING : $error_code : $line\n";
		}
		my @columns = split /\t/, $line;
		if (scalar @columns != 9) {
		    my $error_code = 'invalid_feature_line_must_have_nine_columns';
		    push @{$errors{$error_code}}, [$line_count, $line];
		    warn "WARNING : $error_code : $line\n";
		}
		my ($seqid, $source, $type, $start, $end, $score, $strand,
		    $phase, $att_text) = @columns;
		# Seqid Characters
		if ($seqid =~ /[^a-zA-Z0-9\.:\^\*\$@!\+_\?\-\|]/) {
		    my $error_code = 'invalid_characters_in_seqid_column';
		    push @{$errors{$error_code}}, [$line_count, $line];
		    warn "WARNING : $error_code : ($1) $line\n";
		}
		# Seqid and sequence-region
		if ($pragmas{'sequence-region'} && ! $pragmas{'sequence-region'}{$seqid}) {
		    my $error_code = 'invalid_seqid_column_no_associated_sequence_region';
		    push @{$errors{$error_code}}, [$line_count, $line];
		    warn "WARNING : $error_code : $line\n";
		}
		# Type
		if ($pragmas{'gvf-version'}) {
		    if (! $valid_so_terms{sequence_alteration}{$type}) {
			my $error_code = 'invalid_type_column_must_be_SO_term_or_ID';
			push @{$errors{$error_code}}, [$line_count, $line];
			warn "WARNING : $error_code : $line\n";
		    }
		}
		else {
		    if (! $valid_so_terms{sequence_feature}{$type}) {
			# my $error_code = 'invalid_type_column_must_be_SO_term_or_ID';
			# push @{$errors{$error_code}}, [$line_count, $line];
			# warn "WARNING : $error_code : $line\n";
		    }
		}
		# Start
		if ($start !~ /^\d+$/) {
		    my $error_code = 'invalid_start_column_must_be_positive_integer';
		    push @{$errors{$error_code}}, [$line_count, $line];
		    warn "WARNING : $error_code : $line\n";
		    # Do bounds checking if sequence-region
		}
		# End
		if ($end !~ /^\d+$/) {
		    my $error_code = 'invalid_end_column_must_be_positive_integer';
		    push @{$errors{$error_code}}, [$line_count, $line];
		    warn "WARNING : $error_code : $line\n";
		    # Do bounds checking if sequence-region
		}
		if ($start > $end) {
		    my $error_code = 'invalid_feature_coordinates_start_is_greater_than_end';
		    push @{$errors{$error_code}}, [$line_count, $line];
		    warn "WARNING : $error_code : $line\n";
		}
		# Score
		if ($score ne '.' && $score !~ /^\-?\d+\.?\d*e?\-?\d*$/) {
		    my $error_code = 'invalid_score_column_must_be_real_number';
		    push @{$errors{$error_code}}, [$line_count, $line];
		    warn "WARNING : $error_code : $line\n";
		}
		# Strand
		if ($strand  !~ /^[\.\-+\?]$/) {
		    my $error_code = 'invalid_strand_column';
		    push @{$errors{$error_code}}, [$line_count, $line];
		    warn "WARNING : $error_code : $line\n";
		}
		# Phase
		if ($phase  !~ /^[\.012]$/) {
		    my $error_code = 'invalid_character_in_phase_column';
		    push @{$errors{$error_code}}, [$line_count, $line];
		    warn "WARNING : $error_code : $line\n";
		}
		# Phase && CDS
		if ($type eq 'CDS' && $phase  !~ /^[012]$/) {
		    my $error_code = 'phase_is_required_for_CDS';
		    push @{$errors{$error_code}}, [$line_count, $line];
		    warn "WARNING : $error_code : $line\n";
		}
		# Phase ! CDS
		if ($type ne 'CDS' && $phase  =~ /^[012]$/) {
		    my $error_code = 'phase_is_given_for_non_CDS_feature_type';
		    push @{$errors{$error_code}}, [$line_count, $line];
		    warn "WARNING : $error_code : $line\n";
		}
		# Attributes
		my %attributes;
		my @pairs = split /;/, $att_text;
	      PAIR:
		for my $pair (@pairs) {
		    if ($pair !~ /(=)/) {
			my $error_code = 'attribute_key_value_pairs_must_be_separated_by_equal_sign';
			push @{$errors{$error_code}}, [$line_count, $line];
			warn "WARNING : $error_code : ($pair) $line\n";
			next PAIR;
		    }
		    my ($key, $value) = split /=/, $pair;
		    if (! defined $key || ! defined $value) {
			my $error_code = 'attribute_key_value_pairs_must_have_key_and_value';
			push @{$errors{$error_code}}, [$line_count, $line];
			warn "WARNING : $error_code : $line\n";
			next PAIR;
		    }
		    my @values = split /,/, $value;
		    push @{$attributes{$key}}, @values;
		}
		for my $key (sort keys %attributes) {
		    my @values = @{$attributes{$key}};
		    # ID
		    if ($key eq 'ID') {
			if (scalar @values > 1) {
			    my $error_code = 'invalid_ID_attribute_multiple_values';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    my $all_ids = join ' ', @values;
			    warn "WARNING : $error_code : ($all_ids) $line\n";
			}
			my $id = $values[0];

			# 
			# if (++$feature_ids{$id} > 1) {
			#     my $error_code = 'invalid_ID_attribute_not_unique';
			#     push @{$errors{$error_code}}, [$line_count, $line];
			#     warn "WARNING : $error_code : ($id) $line\n";
			# }

		    }
		    # Name
		    elsif ($key eq 'Name') {
			# No validation on Name values
		    }
		    # Alias
		    elsif ($key eq 'Alias') {
			# No validation on Name values
		    }
		    # Parent
		    elsif ($key eq 'Parent') {
			for my $value (@values) {
			    my $id = $attributes{ID}[0];
			    $parents{$id}{$value}++ if $id;
			}
		    }
		    # Target
		    elsif ($key eq 'Target') {
			if (scalar @values > 1) {
			    my $error_code = 'invalid_Target_attribute_multiple_values';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    my $all_values = join ' ', @values;
			    warn "WARNING : $error_code : ($all_values) $line\n";
			}
			my $value = $values[0];
			if ($value !~ /\S+\s+\d+\s+\d+\s*[\-+]*/) {
			    my $error_code = 'invalid_Target_attribute_value';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    warn "WARNING : $error_code : ($value) $line\n";
			}
		    }
		    # Gap
		    elsif ($key eq 'Gap') {
			if (scalar @values > 1) {
			    my $error_code = 'invalid_Gap_attribute_multiple_values';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    my $all_values = join ' ', @values;
			    warn "WARNING : $error_code : ($all_values) $line\n";
			}
			my $value = $values[0];
			# TODO: Validate the CIGAR format
		    }
		    # Derives_from
		    elsif ($key eq 'Derives_from') {
			if (scalar @values > 1) {
			    my $error_code = 'invalid_Derives_from_attribute_multiple_values';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    my $all_values = join ' ', @values;
			    warn "WARNING : $error_code : ($all_values) $line\n";
			}
			my $value = $values[0];
			# TODO: Validate the Derives_from relationships
		    }
		    # Note
		    elsif ($key eq 'Note') {
			# No validation on Note value
		    }
		    # Dbxref
		    elsif ($key eq 'Dbxref') {
			for my $value (@values) {
			    my ($db, $ID) = split /:/, $value;
			    # TODO: Validate the Dbxref DB and ID;
			}
		    }
		    # Ontology_term
		    elsif ($key eq 'Ontology_term') {
			# TODO: Validate Ontology_term
		    }
		    # Is_circular
		    elsif ($key eq 'Is_circular') {
			if (scalar @values > 1) {
			    my $error_code = 'invalid_Is_circular_attribute_multiple_values';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    my $all_values = join ' ', @values;
			    warn "WARNING : $error_code : ($all_values) $line\n";
			}
			my $value = $values[0];
			# TODO: Validate Is_circular
		    }
		    # Variant_seq
		    elsif ($key eq 'Variant_seq') {
			for my $value (@values) {
			    # TODO: Validate the length of the Variant_seq
			    if ($type eq 'SNV') {
				if ($value !~ /[ATGC]/i) {
				    my $error_code = 'invalid_Variant_seq_attribute_value_for_SNV';
				    push @{$errors{$error_code}}, [$line_count, $line];
				    warn "WARNING : $error_code : ($value) $line\n";
				}
			    }
			    elsif ($type eq 'insertion') {
				if ($value !~ /[ATGCN]+|~/i) {
				    my $error_code = 'invalid_Variant_seq_attribute_value_insertion_indel';
				    push @{$errors{$error_code}}, [$line_count, $line];
				    warn "WARNING : $error_code : ($value) $line\n";
				}

			    }
			    elsif ($type eq 'deletion') {
				if ($value !~ /[ATGCN]+|-/i) {
				    my $error_code = 'invalid_Variant_seq_attribute_value_deletion_indel';
				    push @{$errors{$error_code}}, [$line_count, $line];
				    warn "WARNING : $error_code : ($value) $line\n";
				}

			    }
			    elsif ($type eq 'indel') {
				if ($value !~ /[ATGCN]+|[-~]/i) {
				    my $error_code = 'invalid_Variant_seq_attribute_value_deletion_indel';
				    push @{$errors{$error_code}}, [$line_count, $line];
				    warn "WARNING : $error_code : ($value) $line\n";
				}
			    }
			}
		    }
		    # Reference_seq
		    elsif ($key eq 'Reference_seq') {
			for my $value (@values) {
			    if ($type eq 'SNV') {
				if ($value !~ /[ATGCN]/) {
				    my $error_code = 'invalid_Reference_seq_attribute_value_for_SNV';
				    push @{$errors{$error_code}}, [$line_count, $line];
				    warn "WARNING : $error_code : ($value) $line\n";
				}
			    }
			    elsif ($type eq 'insertion') {
				if ($value !~ /[ATGCN]+|-/) {
				    my $error_code = 'invalid_Reference_seq_attribute_value_insertion_indel';
				    push @{$errors{$error_code}}, [$line_count, $line];
				    warn "WARNING : $error_code : ($value) $line\n";
				}

			    }
			    elsif ($type eq 'deletion') {
				if ($value !~ /[ATGCN]+|~/) {
				    my $error_code = 'invalid_Reference_seq_attribute_value_deletion_indel';
				    push @{$errors{$error_code}}, [$line_count, $line];
				    warn "WARNING : $error_code : ($value) $line\n";
				}

			    }
			    elsif ($type eq 'indel') {
				if ($value !~ /[ATGCN]+|[-~]/) {
				    my $error_code = 'invalid_Reference_seq_attribute_value_deletion_indel';
				    push @{$errors{$error_code}}, [$line_count, $line];
				    warn "WARNING : $error_code : ($value) $line\n";
				}

			    }
			}
		    }
		    # Variant_reads
		    elsif ($key eq 'Variant_reads') {
			for my $value (@values) {
			    if ($value !~ /^\d+$/) {
				my $error_code = 'invalid_Variant_reads_attribute_value';
				push @{$errors{$error_code}}, [$line_count, $line];
				warn "WARNING : $error_code : ($value) $line\n";
			    }
			}
		    }
		    # Total_reads
		    elsif ($key eq 'Total_reads') {
			if (scalar @values > 1) {
			    my $error_code = 'invalid_Total_reads_attribute_multiple_values';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    my $all_values = join ' ', @values;
			    warn "WARNING : $error_code : ($all_values) $line\n";
			}
			my $value = $values[0];
			if ($value !~ /^\d+$/) {
			    my $error_code = 'invalid_Total_reads_attribute_value';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    warn "WARNING : $error_code : ($value) $line\n";
			}
		    }
		    # Genotype
		    elsif ($key eq 'Genotype') {
			if (scalar @values > 1) {
			    my $error_code = 'invalid_Genotype_attribute_multiple_values';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    my $all_values = join ' ', @values;
			    warn "WARNING : $error_code : ($all_values) $line\n";
			}
			my $value = $values[0];
			if ($value !~ /^(hetero|homo|hemi)zygous$/) {
			    my $error_code = 'invalid_Genotype_attribute_value';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    warn "WARNING : $error_code : ($value) $line\n";
			}
		    }
		    # Variant_freq
		    elsif ($key eq 'Variant_freq') {
			for my $value (@values) {
			    if ($value !~ /^\d+\.?\d*\e?\-?\d*/) {
				my $error_code = 'invalid_Variant_freq_attribute_value';
				push @{$errors{$error_code}}, [$line_count, $line];
				warn "WARNING : $error_code : ($value) $line\n";
			    }
			}
		    }
		    # Variant_effect
		    elsif ($key eq 'Variant_effect') {
			my $value = join ' ', @values;
			my ($sequence_variant, $index, $sequence_feature, @featureIDs) = split /\s+/, $value;
			# TODO: Validate $sequence_variant
			if ($index !~ /^\d+$/ || $index > (scalar @{$attributes{Variant_seq}} - 1)) {
			    my $error_code = 'invalid_Variant_effect_attribute_index_value';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    warn "WARNING : $error_code : ($index) $line\n";
			}
			if (! $valid_so_terms{sequence_variant}{$sequence_variant}) {
			    my $error_code = 'invalid_Variant_effect_attribute_sequence_variant_value';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    warn "WARNING : $error_code : ($sequence_variant) $line\n";
			}
			if (! $valid_so_terms{sequence_feature}{$sequence_feature}) {
			    my $error_code = 'invalid_Variant_effect_attribute_sequence_feature_value';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    warn "WARNING : $error_code : ($sequence_feature) $line\n";
			}
			# TODO: Validate featureIDs
		    }
		    # Variant_copy_number
		    elsif ($key eq 'Variant_copy_number') {
			for my $value (@values) {
			    if ($value !~ /^d+$/) {
				my $error_code = 'invalid_attribute_value';
				push @{$errors{$error_code}}, [$line_count, $line];
				warn "WARNING : $error_code : ($value) $line\n";
			    }
			}
		    }
		    # Reference_copy_number
		    elsif ($key eq 'Reference_copy_number') {
			if (scalar @values > 1) {
			    my $error_code = 'invalid_Reference_copy_number_attribute_multiple_values';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    my $all_values = join ' ', @values;
			    warn "WARNING : $error_code : ($all_values) $line\n";
			}
			my $value = $values[0];
			for my $value (@values) {
			    if ($value !~ /^\d+$/) {
				my $error_code = 'invalid_Reference_copy_number_attribute_value';
				push @{$errors{$error_code}}, [$line_count, $line];
				warn "WARNING : $error_code : ($value) $line\n";
			    }
			}
		    }
		    # Start_range
		    elsif ($key eq 'Start_range') {
			if (scalar @values != 2) {
			    my $error_code = 'invalid_Start_range_attribute_must_have_2_values';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    my $all_values = join ',', @values;
			    warn "WARNING : $error_code : ($all_values) $line\n";
			}
			if ($values[0] =~ /^\d+$/ && $values[0] > $start) {
			    my $error_code = 'invalid_Start_range_attribute_values_must_contain_start';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    my $all_values = join ',', @values;
			    warn "WARNING : $error_code : ($all_values, $start) $line\n";
			}
			if ($values[1] =~ /^\d+$/ && $values[1] < $start) {
			    my $error_code = 'invalid_Start_range_attribute_values_must_contain_start';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    my $all_values = join ',', @values;
			    warn "WARNING : $error_code : ($all_values, $start) $line\n";
			}
			for my $value (@values) {
			    if ($value ne '.' && $value !~ /^\d+$/) {
				my $error_code = 'invalid_Start_range_attribute_value';
				push @{$errors{$error_code}}, [$line_count, $line];
				warn "WARNING : $error_code : ($value) $line\n";
			    }
			}
		    }
		    # End_range
		    elsif ($key eq 'End_range') {
			if (scalar @values != 2) {
			    my $error_code = 'invalid_Etart_range_attribute_must_have_2_values';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    my $all_values = join ',', @values;
			    warn "WARNING : $error_code : ($all_values) $line\n";
			}
			if ($values[0] =~ /^\d+$/ && $values[0] > $end) {
			    my $error_code = 'invalid_End_range_attribute_values_must_contain_end';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    my $all_values = join ',', @values;
			    warn "WARNING : $error_code : ($all_values, $end) $line\n";
			}
			if ($values[1] =~ /^\d+$/ && $values[1] < $end) {
			    my $error_code = 'invalid_End_range_attribute_values_must_contain_end';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    my $all_values = join ',', @values;
			    warn "WARNING : $error_code : ($all_values, $end) $line\n";
			}
			for my $value (@values) {
			    if ($value ne '.' && $value !~ /^\d+$/) {
				my $error_code = 'invalid_End_range_attribute_value';
				push @{$errors{$error_code}}, [$line_count, $line];
				warn "WARNING : $error_code : ($value) $line\n";
			    }
			}
		    }
		    # Phased
		    elsif ($key eq 'Phased') {
			if (scalar @values > 1) {
			    my $error_code = 'invalid_Phased_attribute_multiple_values';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    my $all_values = join ' ', @values;
			    warn "WARNING : $error_code : ($all_values) $line\n";
			}
			my $value = $values[0];
			# TODO: Validate the Phased attribute
		    }
		}
	    }
	    # Pragmas
	    else {
		##gff-version
		if ($line =~ /^\#\#gff-version/) {
		    chomp $line;
		    $line_count++;
		    my $seen = {};
		    my $children = {};
		    my %relationships = (is_a    => 1,
					 part_of => 1,
					 );
		    # Get valid sequence_feature terms
		    no warnings;
		    ($seen, $children) = get_so_children($so_data, 'SO:0000110', \%relationships, $seen, $children);
		    %{$valid_so_terms{sequence_feature}} = ('SO:0000110' => 1);
		    use warnings;
		    map {$valid_so_terms{sequence_feature}{$_}++} keys %{$children};
		    map {$valid_so_terms{sequence_feature}{$_}++} @{$so_data->{map}}{keys %{$valid_so_terms{sequence_feature}}};
		    if ($line =~ /^\#\#gff-version\s+(\d+\.?\d*)/) {
			$pragmas{'gff-version'} = $1;
		    }
		    else {
			my $error_code = 'invalid_gff-version_pragma_value';
			push @{$errors{$error_code}}, [$line_count, $line];
			warn "WARNING : $error_code : $line\n";
		    }
		}
		##gvf-version
		elsif ($line =~ /^\#\#gvf-version/) {
		    $line_count++;
		    my $seen = {};
		    my $children = {};
		    my %relationships = (is_a    => 1,
					 part_of => 1,
					 );
		    # Get valid sequence_alteration terms
		    no warnings;
		    ($seen, $children) = get_so_children($so_data, 'SO:0001059', \%relationships, $seen, $children);
		    use warnings;
		    %{$valid_so_terms{sequence_alteration}} = ('SO:0001059' => 1,
							       'SO:0000730' => 1
							       );
		    map {$valid_so_terms{sequence_alteration}{$_}++} keys %{$children};
		    map {$valid_so_terms{sequence_alteration}{$_}++} @{$so_data->{map}}{keys %{$valid_so_terms{sequence_alteration}}};

		    # Get valid sequence_variant terms
		    $seen = {};
		    $children = {};
		    no warnings;
		    ($seen, $children) = get_so_children($so_data, 'SO:0001060', \%relationships, $seen, $children);
		    use warnings;
		    %{$valid_so_terms{sequence_variant}} = ('SO:0001060' => 1);
		    map {$valid_so_terms{sequence_variant}{$_}++} keys %{$children};
		    map {$valid_so_terms{sequence_variant}{$_}++} @{$so_data->{map}}{keys %{$valid_so_terms{sequence_variant}}};

		    if ($line =~ /^\#\#gvf-version\s+(\d+\.?\d*)/) {
			$pragmas{'gvf-version'} = $1;
		    }
		    else {
			my $error_code = 'invalid_gvf-version_pragma_value';
			push @{$errors{$error_code}}, [$line_count, $line];
			warn "WARNING : $error_code : $line\n";
		    }
		}
		##feature-ontology
		elsif ($line =~ /^\#\#feature-ontology/) {
		    if ($line =~ /^\#\#(feature-ontology)\s+(\S+)/) {
			my $pragma_key   = $1;
			my $pragma_value = $2;
			$pragmas{$pragma_key} = $pragma_value;
			# TODO: test_uri($pragma_value);
		    }
		    else {
			my $error_code = 'invalid_pragma_format';
			push @{$errors{$error_code}}, [$line_count, $line];
			warn "WARNING : $error_code : $line\n";
		    }
		}
		##attribute-ontology
		elsif ($line =~ /^\#\#attribute-ontology/) {
		    if ($line =~ /^\#\#(attribute-ontology)\s+(\S+)/) {
			my $pragma_key   = $1;
			my $pragma_value = $2;
			$pragmas{$pragma_key} = $pragma_value;
			#TODO: test_uri($pragma_value);
		    }
		    else {
			my $error_code = 'invalid_pragma_format';
			push @{$errors{$error_code}}, [$line_count, $line];
			warn "WARNING : $error_code : $line\n";
		    }
		}
		##source-ontology
		elsif ($line =~ /^\#\#source-ontology/) {
		    if ($line =~ /^\#\#(source-ontology)\s+(\S+)/) {
			my $pragma_key   = $1;
			my $pragma_value = $2;
			$pragmas{$pragma_key} = $pragma_value;
			#TODO: test_uri($pragma_value);
		    }
		    else {
			my $error_code = 'invalid_pragma_format';
			push @{$errors{$error_code}}, [$line_count, $line];
			warn "WARNING : $error_code : $line\n";
		    }
		}
		##species
		elsif ($line =~ /^\#\#species/) {
		    if ($line =~ /^\#\#(species)\s+(\S+)/) {
			my $pragma_key   = $1;
			my $pragma_value = $2;
			$pragmas{$pragma_key} = $pragma_value;
			# TODO: test_uri($pragma_value);
		    }
		    else {
			my $error_code = 'invalid_pragma_format';
			push @{$errors{$error_code}}, [$line_count, $line];
			warn "WARNING : $error_code : $line\n";
		    }
		}
		##genome-build
		elsif ($line =~ /^\#\#genome-build/) {
		    if ($line =~ /^\#\#(genome-build)\s+(\S+)\s+(\S+)/) {
			my $pragma_key = $1;
			my $source     = $2;
			my $build_name = $3;
			$pragmas{$pragma_key}{$source} = $build_name;
		    }
		    else {
			my $error_code = 'invalid_pragma_format';
			push @{$errors{$error_code}}, [$line_count, $line];
			warn "WARNING : $error_code : $line\n";
		    }
		}
		##sequence-region
		elsif ($line =~ /^\#\#sequence-region/) {
		    if ($line =~ /^\#\#(sequence-region)\s+(\S+)\s+(\d+)\s+(\d+)/) {
			my $pragma_key = $1;
			my $seqid      = $2;
			my $start      = $3;
			my $end        = $4;
			if (! $seqid || ! $start || ! $end) {
			    my $error_code = 'missing_sequence-region_pragma_values';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    warn "WARNING : $error_code : $line\n";
			}
			elsif ($start !~ /^\d+$/ || $end !~ /^\d+$/) {
			    my $error_code = 'invalid_sequence-region_pragma_value';
			    push @{$errors{$error_code}}, [$line_count, $line];
			    warn "WARNING : $error_code : $line\n";
			}
			else {
			    $pragmas{$pragma_key}{$seqid} = [$start, $end];
			}
		    }
		}
		##file-date
		elsif ($line =~ /^\#\#file-date /) {
		    if ($line =~ /^\#\#(file-date)\s+(20[1-9][0-9]-\d\d-\d\d)/) {
			my $pragma_key = $1;
			my $date       = $2;
			$pragmas{$pragma_key} = $date;
		    }
		    else {
			my $error_code = 'invalid_pragma_format';
			push @{$errors{$error_code}}, [$line_count, $line];
			warn "WARNING : $error_code : $line\n";
		    }
		}
		##file-version
		elsif ($line =~ /^\#\#file-version /) {
		    if ($line =~ /^\#\#(file-version)\s+(.*?)/) {
			my $pragma_key = $1;
			my $version    = $2;
			$pragmas{$pragma_key} = $version;
		    }
		    else {
			my $error_code = 'invalid_pragma_format';
			push @{$errors{$error_code}}, [$line_count, $line];
			warn "WARNING : $error_code : $line\n";
		    }
		}
		##individual-id
		elsif ($line =~ /^\#\#individual-id/) {
		    if ($line =~ /^\#\#(individual-id)\s+(\S+.*)/) {
			my $pragma_key   = $1;
			my $pragma_value = $2;
			$pragmas{$pragma_key} = $pragma_value;
		    }
		    else {
			my $error_code = 'invalid_pragma_format';
			push @{$errors{$error_code}}, [$line_count, $line];
			warn "WARNING : $error_code : $line\n";
		    }
		}
		##score-method
		elsif ($line =~ /^\#\#score-method/) {
		    if ($line =~ /^\#\#(score-method)\s+(\S+.*)/) {
			my $pragma_key   = $1;
			my $pragma_value = $2;
			$pragmas{$pragma_key} = $pragma_value;
		    }
		    else {
			my $error_code = 'invalid_pragma_format';
			push @{$errors{$error_code}}, [$line_count, $line];
			warn "WARNING : $error_code : $line\n";
		    }
		}
		##source-method
		elsif ($line =~ /^\#\#source-method/) {
		    if ($line =~ /^\#\#(source-method)\s+(\S+.*)/) {
			my $pragma_key   = $1;
			my $pragma_value = $2;
			$pragmas{$pragma_key} = $pragma_value;
		    }
		    else {
			my $error_code = 'invalid_pragma_format';
			push @{$errors{$error_code}}, [$line_count, $line];
			warn "WARNING : $error_code : $line\n";
		    }
		}
		##attribute-method
		elsif ($line =~ /^\#\#attribute-method/) {
		    if ($line =~ /^\#\#(attribute-method)\s+(\S+.*)/) {
			my $pragma_key   = $1;
			my $pragma_value = $2;
			$pragmas{$pragma_key} = $pragma_value;
		    }
		    else {
			my $error_code = 'invalid_pragma_format';
			push @{$errors{$error_code}}, [$line_count, $line];
			warn "WARNING : $error_code : $line\n";
		    }
		}
		##technology-platform
		elsif ($line =~ /^\#\#technology-platform/) {
		    if ($line =~ /^\#\#(technology-platform)\s+(\S+.*)/) {
			my $pragma_key   = $1;
			my $pragma_value = $2;
			$pragmas{$pragma_key} = $pragma_value;
		    }
		    else {
			my $error_code = 'invalid_pragma_format';
			push @{$errors{$error_code}}, [$line_count, $line];
			warn "WARNING : $error_code : $line\n";
		    }
		}
		##data-source
		elsif ($line =~ /^\#\#data-source/) {
		    if ($line =~ /^\#\#(data-source)\s+(\S+.*)/) {
			my $pragma_key   = $1;
			my $pragma_value = $2;
			$pragmas{$pragma_key} = $pragma_value;
		    }
		    else {
			my $error_code = 'invalid_pragma_format';
			push @{$errors{$error_code}}, [$line_count, $line];
			warn "WARNING : $error_code : $line\n";
		    }
		}
		##phenotype-description
		elsif ($line =~ /^\#\#phenotype-description/) {
		    if ($line =~ /^\#\#(phenotype-description)\s+(\S+.*)/) {
			my $pragma_key   = $1;
			my $pragma_value = $2;
			$pragmas{$pragma_key} = $pragma_value;
		    }
		    else {
			my $error_code = 'invalid_pragma_format';
			push @{$errors{$error_code}}, [$line_count, $line];
			warn "WARNING : $error_code : $line\n";
		    }
		}
		##phased-genotypes
		elsif ($line =~ /^\#\#phased-genotypes/) {
		    if ($line =~ /^\#\#(phased-genotypes)\s+(\S+.*)/) {
			my $pragma_key   = $1;
			my $pragma_value = $2;
			$pragmas{$pragma_key} = $pragma_value;
		    }
		    else {
			my $error_code = 'invalid_pragma_format';
			push @{$errors{$error_code}}, [$line_count, $line];
			warn "WARNING : $error_code : $line\n";
		    }
		}
		###
		elsif ($line =~ /^\#\#\#$/) {
		  # Skip ### - there's no way to further validate it.
		}
		# All other pragmas
		else {
		    $line =~ /^\#\#(\S+)\s*(.*)/;
		    my $pragma_key   = $1;
		    my $pragma_value = $2;
		    my $error_code = 'non_standard_pragma';
		    push @{$errors{$error_code}}, [$line_count, $line];
		    warn "WARNING : $error_code : $line\n";
		    push @{$pragmas{$pragma_key}}, $pragma_value;
		}
	    }
	}

	close $IN;
	print "\n\n";
	print "Error Summary for $file\n";
	print '#' x 80;
	print "\n";
	if (scalar keys %errors) {
	    print "Error Code\tCount\n";
	    for my $error_code (keys %errors) {
		print "$error_code\t" . scalar @{$errors{$error_code}} . "\n";
	    }
	}
	else {
	    print "No Errors found in this file\n";
	}
	print '#' x 80;
	print "\n\n";
    }
}

#-----------------------------------------------------------------------------
#    template	  Pass a Template Toolkit
#                 (http://www.template-toolkit.org/) formatted
#		  template and gff_tool will pass the variant data to
#		  the templating engine.  See the lib/GAL/templates
#		  directory for example templates.
#-----------------------------------------------------------------------------

sub template {

  my ($files, $template) = @_;

  $meta_no = 1;

  eval{require Template};
  if ($@) {
    print "$@\n";
    handle_message('FATAL', 'failed_to_load_module', 'Template');
  }

  eval{require GAL::Base};
  if ($@) {
    print "$@\n";
    handle_message('FATAL', 'failed_to_load_module', 'GAL::Base');
  }

  (my $include_path = $INC{'GAL/Base.pm'}) =~ s/Base.pm$/templates/;
  for my $file (@{$files}) {
    my $tt = Template->new({
			    INCLUDE_PATH => $include_path,
			    ABSOLUTE     => 1,
			    RELATIVE     => 1}) ||
			      handle_message('FATAL', 'failed_to_initialize_template',
					     Template->error());

    my @features;

    my $IN = fh_in($file);
    while (my $f = next_feature_hash($IN)) {
      push @features, $f;
    }

    my $rv = $tt->process($template,
			  {features => \@features},
			 ) || die Template->error();
  }
  exit(0);
}

#-----------------------------------------------------------------------------
#  stats|u	  Return simple summary statistics for the given file.
#		  (Not yet implimented)
#-----------------------------------------------------------------------------

sub stats {

    die "FATAL : feature_not_implimented : gff_tool --stats\n";
    exit;
}


#-----------------------------------------------------------------------------
#  sequence|p     Print a fasta sequence for each feature instead of
#		  the feature. Requires the fasta argument.
#-----------------------------------------------------------------------------

sub sequence {

  my $files = shift;

  for my $file (@{$files}) {
    my $IN  = fh_in($file);
    my $OUT = fh_out($file);
    while (my $f = next_feature_hash($IN, $OUT)) {

      my ($seqid, $start, $end) = @{$f}{qw(seqid start end)};

      my $header = $f->{attributes}{ID}[0];
      my $seq = $FASTA_DB->seq($seqid, $start, $end);

      $seq =~ s/(.{50})/$1\n/g;

      print ">$header\n$seq\n";
    }
  }
  exit;
}

#-----------------------------------------------------------------------------
#  splice_sequence Print the mature fasta sequence for spliced
#  features (exons, CDS)
#-----------------------------------------------------------------------------

sub splice_sequence {

  my $files = shift;

  for my $file (@{$files}) {
    my $IN  = fh_in($file);
    my $OUT = fh_out($file);

    my %spliced_seq;
    while (my $f = next_feature_hash($IN, $OUT)) {

      my $a = $f->{attributes};

      if (exists $a->{Parent}) {
	my @parents = @{$a->{Parent}};

	my ($seqid, $start, $end, $strand) = @{$f}{qw(seqid start end strand)};


	for my $parent (@parents) {
	  push @{$spliced_seq{$parent}{coords}{$seqid}}, [$start, $end];
	  $spliced_seq{$parent}{strand} = $strand;
	}
      }
    }

    for my $id (keys %spliced_seq) {
      my $strand = $spliced_seq{$id}{strand};
      for my $seqid (keys %{$spliced_seq{$id}{coords}}) {
	my @coords;
	if ($strand eq '-') {
	  @coords = sort {$b->[0] <=> $a->[0]} @{$spliced_seq{$id}{coords}{$seqid}};
	}
	else {
	  @coords = sort {$a->[1] <=> $b->[1]} @{$spliced_seq{$id}{coords}{$seqid}};
	}

	my $spliced_seq;
	for my $pair (@coords) {
	  @{$pair} = reverse @{$pair} if $strand eq '-';
	  my $seq = $FASTA_DB->seq($seqid, $pair->[0], $pair->[1]);
	  $spliced_seq .= $seq;
	}
	$spliced_seq =~ s/(.{50})/$1\n/g;
	my $header = "$id";
	print ">$header\n$spliced_seq\n";
	print '';
      }
    }
  }
  exit;
}

#-----------------------------------------------------------------------------
#  fasta_add|q    Add a fasta file to the GFF3 output in a ##FASTA
#		  section.
#-----------------------------------------------------------------------------

sub fasta_add {

    my ($files, $fasta_add) = @_;
    send_message ('WARN',
		  'fasta_add_not_fully_tested',
		  'fasta_add) function is written, but untested'
		  );

    die "FATAL : cant_open_file_for_reading : $fasta_add\n" unless -r $fasta_add;
    for my $file (@{$files}) {
	my ($fasta_section) = `grep -P '^##FASTA' $file`;
	open(my $OUT, '<<', $file) or
	    die "FATAL : cant_open_file_for_reading : $file\n";
	print $OUT "\n## FASTA\n"  unless $fasta_section;
	print $OUT `cat $fasta_add`;
	close $OUT;
    }
    exit;
}

#-----------------------------------------------------------------------------
#  fasta_only|r   Print only the fasta section from a GFF3 file
#-----------------------------------------------------------------------------

sub fasta_only {

    for my $file (@files) {
	open (my $IN, '<', $file) or die "Can't open $file for reading :\n$!\n";
	my $fasta_flag;
	while (<$IN>) {
	  if (/^\#\#\s*FASTA/) {
	    $fasta_flag++;
	    next;
	  }
	  next unless $fasta_flag;
	  print $_;
	}
    }
    exit;
}

#-----------------------------------------------------------------------------
#  fasta_no|R Print the pragmas, comments and features, but not the fasta
#             section from a GFF3 file.
#-----------------------------------------------------------------------------

sub fasta_no {

    warn "\n\ngff_tool (fasta_no) function is written, but untested\n\n";

    for my $file (@files) {
	#unlink $file or die "Can't unlink $file\n$!\n";
	#open (my $OUT, '>', $file) or die "Can't open $file for writing :\n$!\n";
	open (my $IN, '<', $file) or die "Can't open $file for reading :\n$!\n";
	while (<$IN>) {
	    last if /^\#\#\s*FASTA/;
	    print $_;
	}
    }
    exit;
}

#-----------------------------------------------------------------------------
#  add_ID|v        Add ID attributes where they dont already
#		  exist. (Not yet implimented)
#-----------------------------------------------------------------------------

sub add_ID {

    die "gff_tool (add_ID) not yet implimented!\n";
    exit;
}

#-----------------------------------------------------------------------------
#  pragmas|w  Interactively add GFF3/GVF pragmas to the top of the
#		  file.  Use GFF3 or GVF (case insensitive) as an
#		  argument to signify which pragma style to
#		  create. (Not yet implimented)
#-----------------------------------------------------------------------------

sub pragmas {

    die "gff_tool (gff_pragmas) not yet implimented!\n";
    exit;
}

#-----------------------------------------------------------------------------
#  headers_only|y Print only the headers lines (pragmas, comments and
#		  whitespace up to the first feature line) from a GFF
#		  file.
#-----------------------------------------------------------------------------

sub headers_only {

    for my $file (@files) {
	open (my $IN, '<', $file) or die "Can't open $file for reading :\n$!\n";
	my $OUT = fh_out($file);
	while (<$IN>) {
	    last if /^\s*\#\#\s*FASTA/;
	    next unless /^\s*\#/ || /^\s*$/;
	    print $OUT $_;
	}
    }
    exit;
}

#-----------------------------------------------------------------------------
#  headers_no|Y   Print everything except headers lines (pragmas, comments and
#		  whitespace up to the first feature line) from a GFF
#		  file.
#-----------------------------------------------------------------------------

sub headers_no {

    for my $file (@files) {
	open (my $IN, '<', $file) or die "Can't open $file for reading :\n$!\n";
	my $OUT = fh_out($file);
	while (<$IN>) {
	    last if /^\s*\#\#\s*FASTA/;
	    next if /^\s*\#/ || /^\s*$/;
	    print $OUT $_;
	}
    }
    exit;
}

#-----------------------------------------------------------------------------
#  header_add|z    Add a header file to the begining of a GFF file.
#-----------------------------------------------------------------------------

sub meta_add {

    for my $file (@files) {
	open (my $IN, '<', $file) or die "Can't open $file for reading:\n$!\n";
	open (my $HEAD, '<', $meta_add) or die "Can't open $meta_add for reading:\n$!\n";
	my $OUT = fh_out($file);
	print $OUT (<$HEAD>);
	print $OUT (<$IN>);
    }
    exit;
}

#-----------------------------------------------------------------------------
#  features|x     Print only feature lines, removing all headers, comments,
#		  empty lines and fasta from a GFF file.
#-----------------------------------------------------------------------------

sub features {

    for my $file (@files) {
	open (my $IN, '<', $file) or die "Can't open $file for reading:\n$!\n";
	my $OUT = fh_out($file);
	while (<$IN>) {
	    last if /^\s*\#\#\s*FASTA/;
	    next if /^\s*\#/ || /^\s*$/;
	    print $OUT $_;
	}
    }
    exit;
}

#-----------------------------------------------------------------------------
# All coordinate matching set operations are based on
# seqid:start:end unless the set_seq option is set in
# which case it becomes
# seqid:start:end:Reference_seq:Variant_seq.  The
# Reference_seq is removed from the Variant_seq list.
# These set operations are useful, for example, for
# operating on sets of SNVs from a family or
# population.
#-----------------------------------------------------------------------------

#-----------------------------------------------------------------------------
#  union           The union of all files.
#-----------------------------------------------------------------------------

sub union {

    my $files = shift;
    my %union;
    for my $file (@{$files}) {
	my $IN = fh_in($file);
	while (my $f = next_feature_hash($IN)) {
	    my $loc_id  = join ':', @{$f}{qw(seqid start end)};
	    # if ($set_seq) {
	    #	my $a = $f->{attributes};
	    #	my $ref_seq = $a->{Reference_seq}[0];
	    #	my ($var_seq) = grep {$_ ne $ref_seq} @{$a->{Variant_seq}};
	    #	$loc_id = join ':', ($loc_id, $ref_seq, $var_seq);
	    # }
	    $union{$loc_id} ||= $f;
	}
    }
    my $OUT = fh_out();
    for my $loc_id (sort keys %union) {
	my $f = $union{$loc_id};
    }
    exit;
}

#-----------------------------------------------------------------------------
#  intersection    The intersection of all files.
#-----------------------------------------------------------------------------

sub intersection {

    my $files = shift;
    my (%inter_count, %inter_stash);
    my $file_count = 1;
    my $file = shift @{$files};
    my $IN = fh_in($file);
    while (my $f = next_feature_hash($IN)) {
	my $loc_id  = join ':', @{$f}{qw(seqid start end)};
	# if ($set_seq) {
	#	my $a = $f->{attributes};
	#	my $ref_seq = $a->{Reference_seq}[0];
	#	my ($var_seq) = grep {$_ ne $ref_seq} @{$a->{Variant_seq}};
	#	$loc_id = join ':', ($loc_id, $ref_seq, $var_seq);
	# }
	$inter_stash{$loc_id} ||= $f;
	$inter_count{$loc_id}++;
    }
    for my $file (@files) {
	my $IN = fh_in($file);
	$file_count++;
	while (my $f = next_feature_hash($IN)) {
	    my $loc_id  = join ':', @{$f}{qw(seqid start end)};
	    # if ($set_seq) {
	    #	my $a = $f->{attributes};
	    #	my $ref_seq = $a->{Reference_seq}[0];
	    #	my ($var_seq) = grep {$_ ne $ref_seq} @{$a->{Variant_seq}};
	    #	$loc_id = join ':', ($loc_id, $ref_seq, $var_seq);
	    # }
	    $inter_count{$loc_id}++;
	}
    }
    my $OUT = fh_out();
    for my $loc_id (sort keys %inter_stash) {
	if ($inter_count{$loc_id} == $file_count) {
	    my $f = $inter_stash{$loc_id};
	    print $OUT to_gff3($f);
	}
    }
    exit;
}

#-----------------------------------------------------------------------------
#  lcomplement    The members found exclusively in the first file
#                  but not in any subsequent files.
#-----------------------------------------------------------------------------

sub lcomplement {
    my $files = shift;
    my (%comp_stash, %comp_count);
    my %others;
    my $file = shift @{$files};
    my $IN = fh_in($file);
    while (my $f = next_feature_hash($IN)) {
	my $loc_id  = join ':', @{$f}{qw(seqid start end)};
	# if ($set_seq) {
	#   my $a = $f->{attributes};
	#   my $ref_seq = $a->{Reference_seq}[0];
	#   my ($var_seq) = grep {$_ ne $ref_seq} @{$a->{Variant_seq}};
	#   $loc_id = join ':', ($loc_id, $ref_seq, $var_seq);
	# }
	$comp_stash{$loc_id} = $f;
	$comp_count{$loc_id}++;
    }
    for my $file (@files) {
	my $IN = fh_in($file);
	while (my $f = next_feature_hash($IN)) {
	    my $loc_id  = join ':', @{$f}{qw(seqid start end)};
	    # if ($set_seq) {
	    #	my $a = $f->{attributes};
	    #	my $ref_seq = $a->{Reference_seq}[0];
	    #	my ($var_seq) = grep {$_ ne $ref_seq} @{$a->{Variant_seq}};
	    #	$loc_id = join ':', ($loc_id, $ref_seq, $var_seq);
	    # }
	    $comp_count{$loc_id}++;
	}
    }
    my $OUT = fh_out();
    for my $loc_id (sort keys %comp_stash) {
	if ($comp_count{$loc_id} == 1) {
	    next unless exists $comp_stash{$loc_id};
	    my $f = $comp_stash{$loc_id};
	    print $OUT to_gff3($f);
	}
    }
    exit;
}

#-----------------------------------------------------------------------------
#  sdifference    The members found in exactly one file.
#-----------------------------------------------------------------------------

sub sdifference {
    my $files = shift;
    my (%diff_count, %diff_stash);
    for my $file (@files) {
	my $IN = fh_in($file);
	while (my $f = next_feature_hash($IN)) {
	    my $loc_id  = join ':', @{$f}{qw(seqid start end)};
	    # if ($set_seq) {
	    #	my $a = $f->{attributes};
	    #	my $ref_seq = $a->{Reference_seq}[0];
	    #	my ($var_seq) = grep {$_ ne $ref_seq} @{$a->{Variant_seq}};
	    #	$loc_id = join ':', ($loc_id, $ref_seq, $var_seq);
	    # }
	    $diff_stash{$loc_id} ||= $f;
	    $diff_count{$loc_id}++;
	}
    }
    my $OUT = fh_out();
    for my $loc_id (sort keys %diff_stash) {
	if ($diff_count{$loc_id} == 1) {
	    my $f = $diff_stash{$loc_id};
	    print $OUT to_gff3($f);
	}
    }
    exit;
}

#-----------------------------------------------------------------------------
# All interval overlap set operations are based on
# intersecting the genomic intervals occupied by a
# feature and creating new features based on the set
# operation.  These operations are useful, for
# example, in finding the similar or dissimilar
# regions between two sets of exons.
#-----------------------------------------------------------------------------

#-----------------------------------------------------------------------------
#  i_union         Create a new set of features that is the union of
#                  regions between all supplied features.
#-----------------------------------------------------------------------------

sub i_union {

    my $files = shift;

    $meta_no = 1;
    $| = 1;

    my %sets;
    my %order;
    my $counter = 0;
    for my $file (@{$files}) {
	my $IN = fh_in($file);
	while (my $f = next_feature_hash($IN)) {
	    my ($seqid, $start, $end) = @{$f}{qw(seqid start end)};
	    $order{$seqid} ||= $counter++;
	    $sets{$seqid} ||= Set::IntSpan::Fast->new();
	    $sets{$seqid}->add_range($start, $end);
	}
    }
    my $OUT = fh_out();
    $counter = 1;
    for my $seqid (sort {$order{$a} <=> $order{$b}} keys %sets) {
	my $iter = $sets{$seqid}->iterate_runs();
	while (my ( $start, $end ) = $iter->()) {
	    my $feature_id = sprintf('ID_%03d', $counter++);
	    my $region = {feature_id => $feature_id,
			  seqid      => $seqid,
			  source     => '.',
			  type       => 'region',
			  start      => $start,
			  end        => $end,
			  score      => '.',
			  strand     => '.',
			  phase      => '.',
			  attributes => {ID => [$feature_id]}};
	    print $OUT to_gff3($region);
	}
    }
    exit;
}

#-----------------------------------------------------------------------------
#  i_intersection  Create a new set of features that contain only the
#                  regions of intersection between all supplied features.
#-----------------------------------------------------------------------------

sub i_intersection {

    my $files = shift;

    $meta_no = 1;
    $| = 1;

    my %intrsc;
    my %order;
    my $counter = 0;
    my $file = shift @{$files};
    my $IN = fh_in($file);
    while (my $f = next_feature_hash($IN)) {
	my ($seqid, $start, $end) = @{$f}{qw(seqid start end)};
	$order{$seqid} ||= $counter++;
	$intrsc{$seqid} ||= Set::IntSpan::Fast->new();
	$intrsc{$seqid}->add_range($start, $end);
    }

    for my $file (@{$files}) {
	my %set;
	my $IN = fh_in($file);
	while (my $f = next_feature_hash($IN)) {
	    my ($seqid, $start, $end) = @{$f}{qw(seqid start end)};
	    $order{$seqid} ||= $counter++;
	    $set{$seqid} ||= Set::IntSpan::Fast->new();
	    $set{$seqid}->add_range($start, $end);
	}
	for my $seqid (keys %intrsc) {
	    if(! exists $set{$seqid}) {
		delete $intrsc{$seqid};
		next;
	    }
	    $intrsc{$seqid} = $intrsc{$seqid}->intersection($set{$seqid});
	}
    }

    my $OUT = fh_out();
    $counter = 1;
    for my $seqid (sort {$order{$a} <=> $order{$b}} keys %intrsc) {
	my $iter = $intrsc{$seqid}->iterate_runs();
	while (my ( $start, $end ) = $iter->()) {
	    my $feature_id = sprintf('ID_%03d', $counter++);
	    my $region = {feature_id => $feature_id,
			  seqid      => $seqid,
			  source     => '.',
			  type       => 'region',
			  start      => $start,
			  end        => $end,
			  score      => '.',
			  strand     => '.',
			  phase      => '.',
			  attributes => {ID => [$feature_id]}};
	    print $OUT to_gff3($region);
	}
    }
    exit;
}

#-----------------------------------------------------------------------------
#  i_lcomplement   Create a new set of features that contain the
#                  regions found only in the first set of features.
#-----------------------------------------------------------------------------

sub i_lcomplement {

    my $files = shift;

    $meta_no = 1;
    $| = 1;

    my %ldiff;
    my %order;
    my $counter = 0;
    my $file = shift @{$files};
    my $IN = fh_in($file);
    while (my $f = next_feature_hash($IN)) {
	my ($seqid, $start, $end) = @{$f}{qw(seqid start end)};
	$order{$seqid} ||= $counter++;
	$ldiff{$seqid} ||= Set::IntSpan::Fast->new();
	$ldiff{$seqid}->add_range($start, $end);
    }

    for my $file (@{$files}) {
	my %set;
	my $IN = fh_in($file);
	while (my $f = next_feature_hash($IN)) {
	    my ($seqid, $start, $end) = @{$f}{qw(seqid start end)};
	    $order{$seqid} ||= $counter++;
	    $set{$seqid} ||= Set::IntSpan::Fast->new();
	    $set{$seqid}->add_range($start, $end);
	}
	for my $seqid (keys %ldiff) {
	    if(! exists $set{$seqid}) {
		delete $ldiff{$seqid};
		next;
	    }
	    $ldiff{$seqid} = $ldiff{$seqid}->diff($set{$seqid});
	}
    }

    my $OUT = fh_out();
    $counter = 1;
    for my $seqid (sort {$order{$a} <=> $order{$b}} keys %ldiff) {
	my $iter = $ldiff{$seqid}->iterate_runs();
	while (my ( $start, $end ) = $iter->()) {
	    my $feature_id = sprintf('ID_%03d', $counter++);
	    my $region = {feature_id => $feature_id,
			  seqid      => $seqid,
			  source     => '.',
			  type       => 'region',
			  start      => $start,
			  end        => $end,
			  score      => '.',
			  strand     => '.',
			  phase      => '.',
			  attributes => {ID => [$feature_id]}};
	    print $OUT to_gff3($region);
	}
    }
    exit;
}

#-----------------------------------------------------------------------------
#  i_sdifference    Create a new set of features that contain the regions
#                  that are found in one and only one file.
#-----------------------------------------------------------------------------

sub i_sdifference {

    die "gff_tool (gff_pragmas) not yet implimented!\n";
    exit;

#     my $files = shift;
#     my (%diff_count, %diff_stash);
#     for my $file (@files) {
#	my $IN = fh_in($file);
#	while (my $f = next_feature_hash($IN)) {
#	    my $loc_id  = join ':', @{$f}{qw(seqid start end)};
#	    # if ($set_seq) {
#	    #	my $a = $f->{attributes};
#	    #	my $ref_seq = $a->{Reference_seq}[0];
#	    #	my ($var_seq) = grep {$_ ne $ref_seq} @{$a->{Variant_seq}};
#	    #	$loc_id = join ':', ($loc_id, $ref_seq, $var_seq);
#	    # }
#	    $diff_stash{$loc_id} ||= $f;
#	    $diff_count{$loc_id}++;
#	}
#     }
#     my $OUT = fh_out();
#     for my $loc_id (sort keys %diff_stash) {
#	if ($diff_count{$loc_id} == 1) {
#	    my $f = $diff_stash{$loc_id};
#	    print $OUT to_gff3($f);
#	}
#     }
#     exit;
}

#-----------------------------------------------------------------------------
#  gvf_sets       Calculate the pairwise intersection and complement
#                 for all files and the symetric difference for each
#                 file.
#-----------------------------------------------------------------------------

sub gvf_sets {

#     my $files = shift;
#     my (%diff, %comp, %union);
#     for my $file1 (@files) {
#	my $IN = fh_in($file1);
#	while (my $f = next_feature_hash($IN)) {
#	    my $loc_id  = join ':', @{$f}{qw(seqid start end)};
#	    # if ($set_seq) {
#	    #	my $a = $f->{attributes};
#	    #	my $ref_seq = $a->{Reference_seq}[0];
#	    #	my ($var_seq) = grep {$_ ne $ref_seq} @{$a->{Variant_seq}};
#	    #	$loc_id = join ':', ($loc_id, $ref_seq, $var_seq);
#	    # }
#	    $diff_stash{$loc_id} ||= $f;
#	    $diff_count{$loc_id}++;
#	}
#	for my $file2 (@files) {
#	    my $IN = fh_in($file2);
#	    while (my $f = next_feature_hash($IN)) {
#     }
#     my $OUT = fh_out();
#     for my $loc_id (sort keys %diff_stash) {
#	if ($diff_count{$loc_id} == 1) {
#	    my $f = $diff_stash{$loc_id};
#	    print $OUT to_gff3($f);
#	}
#     }
  exit;
}

#-----------------------------------------------------------------------------
# fix_gvf
#
# Fix up some common errors in GVF files.  Currently it changes
# Genotype=(hetero|homo)zygous attributes to
# Zygosity=(hetero|homo)zygous uniques the Variant_seq values and
# removes homozygous reference variants.
#
#-----------------------------------------------------------------------------

sub fix_gvf {

  my $files = shift;
  my ($ti, $tv);

  for my $file (@files) {
    my $IN = fh_in($file);
    my $OUT = fh_out($file);
    print_pragmas($IN, $OUT);
  VARIANT:
    while (my $f = next_feature_hash($IN, $OUT)) {
      my $a = $f->{attributes};

      # Fix Genotype
      my $genotype = $a->{Genotype};
      if (grep {/zygous$/} @{$genotype}) {
	$a->{Zygosity} = $a->{Genotype};
	delete $a->{Genotype};
      }

      # Unique Variant_seq
      @{$a->{Variant_seq}} = List::MoreUtils::uniq(@{$a->{Variant_seq}});

      # Remove homozygous reference
      my $ref_seq = $a->{Reference_seq}[0];
      my ($var_seq) = grep {$_ ne $ref_seq} @{$a->{Variant_seq}};

      next VARIANT unless $var_seq;
      print $OUT to_gff3($f);
    }
  }
}

#-----------------------------------------------------------------------------
#  add_ref_seq
#
# Add the value for the Reference_seq attribute.  This option requires
# a numerical value which indicates the length of sequence to be
# represented.  Any sequence longer than the given value will be
# represented by ~# where '\#' will be the length of the sequence.  If
# a value of 0 is provided then all sequences will be reporesented
# full length.  The add_ref_seq function requires that a FASTA
# formatted sequence file be passed to the --fasta argument.  This
# function will read seqeunce from the fasta file for the range
# specified by start and end (columns 4 and 5) and will add or update
# the Reference_seq attribute to contain that sequence, representing
# longer sequences with ~ as described above.
#-----------------------------------------------------------------------------

sub add_ref_seq {

  my ($files, $add_ref_seq) = @_;

  for my $file (@files) {
    my $IN = fh_in($file);
    my $OUT = fh_out($file);
    print_pragmas($IN, $OUT);

    my %zero_length = map {$_ => 1} qw(
					insertion
					duplication
					distal_duplication
					tandem_duplication
					direct_tandem_duplication
					inverted_tandem_duplication
					mobile_element_insertion
					novel_sequence_insertion
					transgenic_insertion
					rearrangement_breakpoint
					interchromosomal_breakpoint
					intrachromosomal_breakpoint
				     );

  VARIANT:
    while (my $f = next_feature_hash($IN, $OUT)) {
      my $a = $f->{attributes};

      my $type = $f->{type};

      my $ref_seq;
      if (exists $zero_length{$type}) {
	$ref_seq = '-';
      }
      else {
	$ref_seq = uc $FASTA_DB->seq(@{$f}{qw(seqid start end)});
      }

      $ref_seq ||= '.';
      $a->{Reference_seq} = [$ref_seq];

      print $OUT to_gff3($f);
    }
  }
}

#-----------------------------------------------------------------------------
#  gvf2vcf        Convert single GVF files to VCF format.  This is a
#                 minimal converter that will convert SNVs and simple
#                 indels with minimal support for extended VCF options.
#-----------------------------------------------------------------------------

sub gvf2vcf {

  $meta_no = 1;

  my ($files) = @_;

  for my $file (@files) {
    my $IN = fh_in($file);
    my $OUT = fh_out($file);

  VARIANT:
    while (my $f = next_feature_hash($IN, $OUT)) {

      # chr7 HGMD SNV 117149137 117149137 . + . ID=HGMD_SNV_012309;Variant_seq=A,G;Reference_seq=G;Genotype=0:1;
      # chrY 28725875 . G . . PASS END=28725892;BLOCKAVG_min30p3a GT:DP:GQX:MQ 0/0:25:75:60

      my ($seqid, $type, $start) = @{$f}{qw(seqid type start)};
      my $a = $f->{attributes};
      my $ref = $a->{Reference_seq}[0];
      my @var_seqs = @{$a->{Variant_seq}};

      if (grep {$_ eq '-'} ($ref, @var_seqs)) {
	my $xtra = uc $FASTA_DB->seq($seqid, $start - 1, $start - 1);
	map {$_ = $xtra . $_;$_ =~ s/-//g} ($ref, @var_seqs);
	$start--;
      }

      my $alt = join ',', grep {$_ ne $ref} @var_seqs;

      my $attribute_text;
      for my $key (sort keys %{$a}) {
	my $value_text = join ',', @{$a->{$key}};
	$attribute_text .= "$key=$value_text;";
      }

      my $info = "SO_TYPE=$type;$attribute_text";
      my @genotypes;

      push @var_seqs, $var_seqs[0] if scalar @var_seqs == 1;
      for my $count (0 .. $#var_seqs) {
	push @genotypes, ($var_seqs[$count] eq $ref ? 0 : $count + 1);
      }
      my $genotype = join '/', (sort @genotypes);

      print $OUT join "\t", ($seqid,
			     $start,
			     $a->{ID}[0],
			     $ref,
			     $alt,
			     $f->{score},
			     '.',
			     $info,
			     'GT',
			     $genotype);
      print $OUT "\n";
    }
  }
}

#-----------------------------------------------------------------------------
#  titv           Calculate transition/transversion ratio.
#-----------------------------------------------------------------------------

sub calc_titv {

    my $files = shift;
    my ($ti, $tv);

    for my $file (@files) {
	my $IN = fh_in($file);
	print "$file\t";
	($ti, $tv) = ();
	while (my $f = next_feature_hash($IN)) {
	    my $a = $f->{attributes};
	    my $ref_seq = $a->{Reference_seq}[0];
	    my ($var_seq) = grep {$_ ne $ref_seq} @{$a->{Variant_seq}};
	    if ($ref_seq eq 'A') {
		if ($var_seq eq 'C') {
		    $tv++;
		}
		elsif ($var_seq eq 'G') {
		    $ti++;
		}
		elsif ($var_seq eq 'T') {
		    $tv++;
		}
		else {
		    my $line = to_gff3($f);
 		    warn "WARNING : variant_seq_not_handled: $line";
		}
	    }
	    elsif ($ref_seq eq 'C') {
		if ($var_seq eq 'A') {
		    $tv++;
		}
		elsif ($var_seq eq 'G') {
		    $tv++;
		}
		elsif ($var_seq eq 'T') {
		    $ti++;
		}
		else {
		    my $line = to_gff3($f);
		    warn "WARNING : variant_seq_not_handled: $line";
		}
	    }
	    elsif ($ref_seq eq 'G') {
		if ($var_seq eq 'A') {
		    $ti++;
		}
		elsif ($var_seq eq 'C') {
		    $tv++;
		}
		elsif ($var_seq eq 'T') {
		    $tv++;
		}
		else {
		    my $line = to_gff3($f);
		    warn "WARNING : variant_seq_not_handled: $line";
		}
	    }
	    elsif ($ref_seq eq 'T') {
		if ($var_seq eq 'A') {
		    $tv++;
		}
		elsif ($var_seq eq 'C') {
		    $ti++;
		}
		elsif ($var_seq eq 'G') {
		    $tv++;
		}
		else {
		    my $line = to_gff3($f);
		    warn "WARNING : variant_seq_not_handled: $line";
		}
	    }
	    else {
		my $line = to_gff3($f);
		warn "WARNING : reference_seq_not_handled: $line";
	    }
	}
	my $ti_tv_ratio = $tv ? $ti/$tv : 'NaN';
	print join "\t", ($ti, $tv, $ti_tv_ratio);
	print "\n";
    }
    exit;
}


#-----------------------------------------------------------------------------
#  gvf_stats           Simple SNV stats on a GVF file.
#-----------------------------------------------------------------------------

sub gvf_stats {

    my $files = shift;
    my ($count, $nc_count, $score, $score_count, $score30p, $ti, $tv, $het, $hom);

    $meta_no = 1;
    $| = 1;

    print join "\t", qw(File Count No-calls 1stQrt_Score Median_Score 3rdQrt_Score %Q>30 Het/Hom Ti/Tv);
    print "\n";
    for my $file (@files) {
	my $IN = fh_in($file);
	my $stat = Statistics::Descriptive::Full->new();
	($count, $nc_count, $score, $score30p, $ti, $tv, $het, $hom) = (0,0,0,0,0,0,0,0);
	$score_count = 0;
      FEATURE:
	while (my $f = next_feature_hash($IN)) {
	    next FEATURE unless $f->{type} eq 'SNV';
	    my $a = $f->{attributes};
	    next FEATURE unless ref $a->{Variant_seq} eq 'ARRAY';
	    unless (grep {/[^\^]/} @{$a->{Variant_seq}}) {
		$nc_count++;
		next FEATURE;
	    }
	    next unless ref $a->{Reference_seq} eq 'ARRAY';
	    $count++;
	    if ($f->{score} =~ /\d+/) {
		$stat->add_data($f->{score});
		$score_count++;
		$score30p++ if $f->{score} >= 30;
	    }
	    if (scalar @{$a->{Variant_seq}} > 1) {
		$het++;
	    }
	    else {
		$hom++;
	    }
	    my $ref_seq = $a->{Reference_seq}[0];
	    my ($var_seq) = grep {$_ ne $ref_seq} @{$a->{Variant_seq}};
	    if ($ref_seq eq 'A') {
		if ($var_seq eq 'C') {
		    $tv++;
		}
		elsif ($var_seq eq 'G') {
		    $ti++;
		}
		elsif ($var_seq eq 'T') {
		    $tv++;
		}
		elsif ($var_seq =~ /[\^.~!]/) {
		    # Skip these for now.
		}
		else {
		    my $line = to_gff3($f);
		    warn "WARNING : variant_seq_not_handled: $line";
		}
	    }
	    elsif ($ref_seq eq 'C') {
		if ($var_seq eq 'A') {
		    $tv++;
		}
		elsif ($var_seq eq 'G') {
		    $tv++;
		}
		elsif ($var_seq eq 'T') {
		    $ti++;
		}
		elsif ($var_seq =~ /[\^.~!]/) {
		    # Skip these for now.
		}
		else {
		    my $line = to_gff3($f);
		    warn "WARNING : variant_seq_not_handled: $line";
		}
	    }
	    elsif ($ref_seq eq 'G') {
		if ($var_seq eq 'A') {
		    $ti++;
		}
		elsif ($var_seq eq 'C') {
		    $tv++;
		}
		elsif ($var_seq eq 'T') {
		    $tv++;
		}
		elsif ($var_seq =~ /[\^.~!]/) {
		    # Skip these for now.
		}
		else {
		    my $line = to_gff3($f);
		    warn "WARNING : variant_seq_not_handled: $line";
		}
	    }
	    elsif ($ref_seq eq 'T') {
		if ($var_seq eq 'A') {
		    $tv++;
		}
		elsif ($var_seq eq 'C') {
		    $ti++;
		}
		elsif ($var_seq eq 'G') {
		    $tv++;
		}
		elsif ($var_seq =~ /[\^.~!]/) {
		    # Skip these for now.
		}
		else {
		    my $line = to_gff3($f);
		    warn "WARNING : variant_seq_not_handled: $line";
		}
	    }
	    else {
		my $line = to_gff3($f);
		warn "WARNING : reference_seq_not_handled: $line";
	    }
	}

	my $scoreQ1;
	my $scoreQ2;
	my $scoreQ3;
	if ($score_count/$count >= 0.3333333) {
	    $scoreQ1 = $stat->percentile(25);
	    $scoreQ2 = $stat->percentile(50);
	    $scoreQ3 = $stat->percentile(75);
	    $score30p = sprintf("%.3f", $score30p / $score_count * 100);
	}
	else {
	    warn ("WARN : too_few_variants_have_quality : " .
		  "Only $score_count variants had quality " .
		  "values.  Not calculating average QUAL.\n");
	}
	$hom = 0 if ! defined $hom;
	$het = 0 if ! defined $het;
	$scoreQ1 ||= '.';
	$scoreQ2 ||= '.';
	$scoreQ3 ||= '.';
	$score30p ||= '.';
	my $het_hom_ratio = $hom ? sprintf("%.3f",$het/$hom)              : '.';
	my $pct_het       = $hom ? sprintf("%.3f",$het/($het + $hom)*100) : '.';
	my $ti_tv_ratio   = $tv  ? sprintf("%.3f",$ti/$tv)                : '.';
	print join "\t", ($file, $count, $nc_count, $scoreQ1, $scoreQ2, $scoreQ3, $score30p, $het_hom_ratio, $ti_tv_ratio);
	print "\n";
    }
    exit;
}

#-----------------------------------------------------------------------------
# effect_stats   Category counts for Variant_effect terms.
#-----------------------------------------------------------------------------

sub effect_stats {

    my $files = shift;

    $meta_no = 1;
    $| = 1;

    my (%files, %terms, %term_total);
    for my $file (@files) {
	$files{$file}++;
	my $IN = fh_in($file);
	while (my $f = next_feature_hash($IN)) {
	    my $effects = $f->{attributes}{Variant_effect} || [];
	    for my $term (@{$effects}) {
		$term =~ s/(\S+).*/$1/;
		$terms{$file}{$term}++;
		$term_total{$term}++;
	    }
	}
    }

    print "File\t";
    print join "\t", sort keys %term_total;
    print "\n";
    for my $file (sort {$terms{$b} <=> $terms{$a}} keys %terms) {
	print "$file";
	for my $term (sort keys %term_total) {
	    my $count = $terms{$file}{$term} || 0;
	    print "\t$count";
	}
	print "\n";
    }
    exit;
}

#-----------------------------------------------------------------------------

sub parse_ids {

  my $file = shift;

  my %ids;
  if ($file && ! -r $file) {
    warn "WARN : assuming_id_name : Assuming $file is an ID";
    $ids{$file}++;
    return \%ids;
  }

  open (my $IN, "<", $file) or
    die "Can't open $file for reading: $!\n";

  %ids = map {chomp;$_ => 1} (<$IN>);

  return \%ids;
}


#-----------------------------------------------------------------------------

sub parse_fasta {

  my $path = shift;

  require Bio::DB::Fasta;

  my $db = Bio::DB::Fasta->new($path);

  return $db;
}

#-----------------------------------------------------------------------------

sub get_sequence_code_ref {

  my ($feature, $db) = @_;

  return
    sub {
      my ($seqid, $start, $end) = @{$feature}{qw(seqid start end)};
      return $db->seq($seqid, $start, $end);
    }
  }

#-----------------------------------------------------------------------------

sub fails_filters {

	my $feature = shift;

	my $fail;

	#Move the filter sub code here


	if ($IDS && %{$IDS}) {
	    $fail++ if ($include && ! $IDS->{$feature->{feature_id}});
	    $fail++ if ($exclude &&   $IDS->{$feature->{feature_id}});
	}
	if ($SEQIDS && %{$SEQIDS}) {
	    $fail++ if ($include && ! $SEQIDS->{$feature->{seqid}});
	    $fail++ if ($exclude &&   $SEQIDS->{$feature->{seqid}});
	}
	return $fail;
}

#-----------------------------------------------------------------------------

sub print_gff {

    my $files = shift;

    for my $file (@files) {
	my $IN = fh_in($file);
	my $OUT = fh_out($file);
	while (my $f = next_feature_hash($IN, $OUT)) {
	    next if fails_filters($f);
	    print $OUT to_gff3($f);
	}
    }
}

#-----------------------------------------------------------------------------

sub print_data {

  my ($files, $data) = @_;

  my @data_keys = split ',', $data;
  my %valid_columns = (seqid  => 1,
		       source => 1,
		       type   => 1,
		       start  => 1,
		       end    => 1,
		       score  => 1,
		       strand => 1,
		       phase  => 1,
		       attributes => 1,
		       #length     => 1,
		       #locus      => 1,
		       #genotype   => 1
		      );

  my %calculate = (length   => 1,
		   locus    => 1,
		   genotype => 1,
		  );

  map {$calculate{$_}++ if exists $calculate{$_}} @data_keys;

  for my $file (@files) {
    my $IN = fh_in($file);
    my $OUT = fh_out($file);
    while (my $f = next_feature_hash($IN, $OUT)) {
      next if fails_filters($f);
      my @this_data;
      for my $data_key (@data_keys) {
	# Handle standard columns
	if (exists $valid_columns{$data_key}) {
	  push @this_data, $f->{$data_key};
	}
	# Create calculated fields
	elsif (exists $calculate{$data_key}) {
	  # Create length
	  if ($data_key eq 'length') {
	    push @this_data, $f->{end} - $f->{start} + 1;
	  }
	  # Create locus
	  elsif ($data_key eq 'locus') {
	    push @this_data, ($f->{seqid} . ':' . $f->{start} . '-'
			      . $f->{end});
	  }
	  # Create genotype
	  elsif ($data_key eq 'genotype') {
	    # Warn of missing Variant_seq
	    if (! exists $f->{attributes}{Variant_seq} ||
		ref $f->{attributes}{Variant_seq} ne 'ARRAY') {
	      print STDERR "WARN : skipping_missing_or_invalid_variant_seq : to_gff3($f) : $data_key\n";
	    }
	    # Create genotype
	    else {
	      my $var_seq = $f->{attributes}{Variant_seq};
	      $var_seq->[1] = $var_seq->[0] unless $var_seq->[1];
	      my $value = join ',', @{$var_seq};
	      push @this_data, $value;
	    }
	  }
	  else {
	    print STDERR "FATAL : invalid_key_value : " . to_gff3($f);
	  }
	}
	# Handle attributes
	else {
	  my $key_copy = $data_key;
	  $key_copy =~ s/^\+//;
	    if (! exists $f->{attributes}{$key_copy}) {
		push @this_data, '';
	    }
	  elsif (ref $f->{attributes}{$key_copy} ne 'ARRAY') {
	      die STDERR ("FATAL : skipping_invalid_attribute_value : " .
			  "($data_key) " . to_gff3($f) . "\n");
	  }
	  else {
	    my $value = join ',', @{$f->{attributes}{$key_copy}};
	    push @this_data, $value;
	  }
	}
      }
      if (grep {length} @this_data) {
	  print join "\t", @this_data;
	  print "\n";
      }
    }
    print '';
  }
  print '';
  exit(0);
}

#-----------------------------------------------------------------------------

sub fh_in {

    my $file = shift;

    my $IN;
    if ($file eq '-') {
	open ($IN, "<&=STDIN")   or die "Can't open STDIN:\n$!\n";
    }
    elsif ($file) {
	open ($IN, "<", $file)   or die "Can't open $file for reading: $!\n";
    }
    else {
	return undef;
    }

    return $IN;
}

#-----------------------------------------------------------------------------

sub fh_out {

    my $file = shift;

    my $OUT;
    if ($in_place && $file) {
	unlink $file;
	open ($OUT, ">", $file)   or die "Can't open $file for writing:\n$!\n";
    }
    elsif ($out_ext && $file) {
	$file .= $out_ext;
	open ($OUT, ">", $file)   or die "Can't open $file for writing:\n$!\n";
    }
    else {
	open ($OUT, ">&=STDOUT") or die "Can't open STDOUT for writing:\n$!\n";
    }
    return $OUT;
}

#-----------------------------------------------------------------------------

sub read_pragmas {

    my $fh = shift;

    my @pragmas;
    my $line = <$fh>;
    my $last_offset = tell($fh) - length($line);
    if (! defined $line) {
	return wantarray ? @pragmas : \@pragmas;
    }

  PRAGMA:
    until ($line !~ /^(\#.*|\s+)$/) {
	next PRAGMA unless $line =~ /^\#/;
	chomp $line;
	if ($line =~ /^\#\#FASTA/) {
	    handle_fasta($fh);
	    return undef;
	}

	# Deal with ###
	if ($line =~ /^\#\#\#\s*$/) {
	  $line = <$fh>;
	  $last_offset = tell($fh) - length($line);
	  next PRAGMA;
	}

	if ($line =~ /^\#\#sequence-region\s(\S+)/) {
	    if ($include && %{$SEQIDS} ) {
		return unless $SEQIDS->{$1};
	    }
	    elsif ($exclude && %{$SEQIDS}) {
		return if $SEQIDS->{$1};
	    }
	}
	push @pragmas, $line;
	$line = <$fh>;
	$last_offset = tell($fh) - length($line);
	last PRAGMA unless defined $line;
    }
    seek($fh, $last_offset, 0);
    return wantarray ? @pragmas : \@pragmas;
}

#-----------------------------------------------------------------------------

sub print_pragmas {

    my ($IN, $OUT) = @_;

    my @pragmas = read_pragmas($IN);
    for my $pragma (@pragmas) {
	print $OUT "$pragma\n";
    }
    print '';
}

#-----------------------------------------------------------------------------

sub next_feature_hash {

    my ($IN, $OUT) = @_;

    my $line = <$IN>;
    return undef unless defined $line;

    until ($line !~ /^(\#.*|\s+)$/) {
	handle_header_line($line, $IN, $OUT);
	$line = <$IN>;
	return undef unless defined $line;
    }
    chomp $line;

    my %feature;
    @feature{qw(seqid source type start end score strand phase attributes)} =
	split /\t/, $line;

    my %attributes;
    my $att_text = $feature{attributes};
    my @pairs = split /;/, $att_text;
    if (! defined $att_text) {
	warn "Warn : no_attributes : ($att_text) $line\n" unless defined $att_text;
    }
    for my $pair (@pairs) {
	my ($key, $value_text) = split /=/, $pair;
	if (! defined $key || ! defined $value_text) {
	    warn "Warn : attribute_with_no_key : ($pair) $line\n"
		unless defined $key;
	    warn "Warn : attribute_with_no_value : ($pair) $line\n"
		unless defined $value_text;
	    next;
	}
	my @values = split ',', $value_text;
	push @{$attributes{$key}}, @values;
    }
    $feature{feature_id} = $attributes{ID}[0];
    $feature{attributes} = \%attributes;
    return wantarray ? %feature : \%feature;
}

#-----------------------------------------------------------------------------

sub handle_header_line {

    my ($line, $IN, $OUT) = @_;

    if ($line =~ /^\#\#FASTA/) {
	handle_fasta($IN, $OUT);
	return undef;
    }

    return undef if $meta_no;
    return undef if $line =~ /^\#\#\#\s*$/;

    if ($line =~ /^\#\#sequence-region\s(\S+)/) {
	if ($include && %{$SEQIDS} ) {
	    return unless $SEQIDS->{$1};
	}
	elsif ($exclude && %{$SEQIDS}) {
	    return if $SEQIDS->{$1};
	}
    }
    print $OUT $line;
}

#-----------------------------------------------------------------------------

sub handle_fasta {

    my ($IN, $OUT) = @_;

    if ($fasta_no) {
      my $line = <$IN>;
      print STDERR "WARN : skipping_fasta_sequence : $line\n";
      while (my $line = <$IN>) {
	next unless $line;
	chomp $line;
	if ($line =~ /^>/) {
	  print STDERR "WARN : skipping_fasta_sequence : $line\n";
	  next;
	}
	if ($line !~ /^[ATGCN]*$/i) {
	  print STDERR "FATAL : non_standard_fasta_line : $line\n";
	}
      }
      return undef;
    }

    require Bio::SeqIO;

    my $seq_io  = Bio::SeqIO->new(-fh => $IN,
				  -format => 'Fasta');

    print $OUT "\n##FASTA\n";
    while (my $seq_obj = $seq_io->next_seq) {
	my $id = $seq_obj->display_id;
	if ($include && scalar keys %{$SEQIDS} ) {
	    next unless $SEQIDS->{$id};
	}
	elsif ($exclude && scalar keys %{$SEQIDS}) {
	    next if $SEQIDS->{$id};
	}
	my $header = $id . " " . $seq_obj->description;
	my $seq = $seq_obj->seq;
	$seq =~ s/(.{60})/$1\n/g;
	print $OUT ">$header\n$seq\n";
    }
    close $IN;
}

#-----------------------------------------------------------------------------

sub to_gff3 {

    my $features = shift;

    my %ATTRB_ORDER = (ID                    => 1,
		       Name                  => 2,
		       Alias                 => 3,
		       Parent                => 4,
		       Target                => 5,
		       Gap                   => 6,
		       Derives_from          => 7,
		       Note                  => 8,
		       Dbxref                => 9,
		       Ontology_term         => 10,
		       Variant_seq           => 11,
		       Reference_seq         => 12,
		       Variant_reads         => 13,
		       Total_reads	     => 14,
		       Genotype		     => 15,
		       Variant_effect        => 16,
		       Variant_copy_number   => 17,
		       Reference_copy_number => 18,
		       );

    $features = [$features] unless ref $features eq 'ARRAY';

    my $gff3_text;
    for my $feature (@{$features}) {
	my $attribute_text;
	for my $key (sort {($ATTRB_ORDER{$a} || 99) <=> ($ATTRB_ORDER{$b} || 99) ||
			       $a cmp $b}
		     keys %{$feature->{attributes}}) {
	    my $value_text = join ',', @{$feature->{attributes}{$key}};
	    $attribute_text .= "$key=$value_text;";
	}

	my $feature_text = join "\t", ($feature->{seqid},
				    $feature->{source},
				    $feature->{type},
				    $feature->{start},
				    $feature->{end},
				    $feature->{score},
				    $feature->{strand},
				    $feature->{phase},
				    $attribute_text,
				    );

	$gff3_text .= "$feature_text\n";
    }
    return $gff3_text;
}

#-----------------------------------------------------------------------------

sub parse_so_file {

    $SO_FILE ||= $ENV{SO_OBO};
    $SO_FILE ||= 'curl -sL http://purl.obolibrary.org/obo/so.obo |';
    open (my $IN, $SO_FILE) or die "FATAL : cant_open_file : $SO_FILE\n";

    my $text = join '', (<$IN>);

    die "FATAL : no_SO_data_available : $SO_FILE (consider using --so_file or check file contents)\n"
      unless $text;

    $text =~ s/.*?\[Term\]/\[Term\]/s;

    my @terms_array = $text =~ /^\[Term\]\n(.*?)\n{2,}/msg;

    my %terms;
    my %map;
    my %graph;
    for my $term_text (@terms_array) {
	my %term;
	my @pairs = split /\n/, $term_text;
	for my $pair (@pairs) {
	    my ($tag, $value) = split /:\s+/, $pair;
	    push @{$term{$tag}}, $value;
	}
	my $id   = $term{id}[0];
	my $name = $term{name}[0];
	$terms{$id} = \%term;
	$map{$name} = $id;
	$map{$id}   = $name;
	$term{is_a} ||= [];
	for my $is_a (@{$term{is_a}}) {
	    my ($is_a_object) = split /\s/, $is_a;
	    $graph{$is_a_object}{is_a}{$id}++;
	}
	$term{relationship} ||= [];
	for my $relationship (@{$term{relationship}}) {
	    my ($predicate, $object) = split /\s+/, $relationship;
	    $graph{$object}{$predicate}{$id}++;
	}
    }
    my %so_data = (terms => \%terms,
		   map   => \%map,
		   graph => \%graph,
		   );

    return \%so_data;
}

#-----------------------------------------------------------------------------

sub get_so_children {

    my ($so_data, $term_id, $relationships, $seen, $children) = @_;

    $term_id = $so_data->{map}{$term_id} unless $term_id =~ /^SO:\d{7}/;
    my $term = $so_data->{terms}{$term_id};

    for my $relationship (keys %{$relationships}) {
	next unless $so_data->{graph}{$term_id}{$relationship};
	map {$children->{$_}++}
	    keys %{$so_data->{graph}{$term_id}{$relationship}};
    }

#    my %these_relationships;
#    $these_relationships{$so_data->{graph}{$term_id}{is_a}}++
#	if $relationships->{is_a};
#    my @more_relationships = @{$so_data->{graph}{$term_id}{relationships}}
#        if exists $so_data->{graph}{$term_id}{relationships};
#    for my $relationship (@more_relationships) {
#	$these_relationships{$so_data->{graph}{$term_id}{relationship}}++;
#    }
#
#    my %these_children;
#    for my $relationship (keys %these_relationships) {
#	map {$these_children{$_}++; $children->{$_}++} @{$term->{relationships}{$relationship}};
#    }


    for my $child (keys %{$children}) {
	next if $seen->{$child};
	$seen->{$child}++;
	my ($seen, $children) = get_so_children($so_data, $child,
						$relationships, $seen,
						$children);
    }
    return ($seen, $children);
}

#-----------------------------------------------------------------------------

sub send_message {

    my ($class, $code, @comments) = @_;

    $class ||= 'WARN';
    $code  ||= 'unknown_warning';
    my $comment = join ' ', @comments;

    my $message = join ' : ', ($class, $code, $comment);
    $message .= "\n";
    $message =~ s/\n+$/\n/;

    print STDERR $message;

}

#-----------------------------------------------------------------------------

sub gff_pragmas {


}

#-----------------------------------------------------------------------------

sub gvf_pragmas {


}

#-----------------------------------------------------------------------------

__END__


    elsif ($build eq 'hg18') {
	  %chrs = (chr1  => 247249719,
		   chr2  => 242951149,
		   chr3  => 199501827,
		   chr4  => 191273063,
		   chr5  => 180857866,
		   chr6  => 170899992,
		   chr7  => 158821424,
		   chr8  => 146274826,
		   chr9  => 140273252,
		   chr10 => 135374737,
		   chr11 => 134452384,
		   chr12 => 132349534,
		   chr13 => 114142980,
		   chr14 => 106368585,
		   chr15 => 100338915,
		   chr16 => 88827254,
		   chr17 => 78774742,
		   chr18 => 76117153,
		   chr19 => 63811651,
		   chr20 => 62435964,
		   chr21 => 46944323,
		   chr22 => 49691432,
		   chrX  => 154913754,
		   chrY  => 57772954,
		   chrM  => 16571,
		   );

	  elsif ($build eq 'hg19') {
	  %chrs = (chr1  => 249250621,
		   chr2  => 243199373,
		   chr3  => 198022430,
		   chr4  => 191154276,
		   chr5  => 180915260,
		   chr6  => 171115067,
		   chr7  => 159138663,
		   chr8  => 146364022,
		   chr9  => 141213431,
		   chr10 => 135534747,
		   chr11 => 135006516,
		   chr12 => 133851895,
		   chr13 => 115169878,
		   chr14 => 107349540,
		   chr15 => 102531392,
		   chr16 => 90354753,
		   chr17 => 81195210,
		   chr18 => 78077248,
		   chr19 => 59128983,
		   chr20 => 63025520,
		   chr21 => 48129895,
		   chr22 => 51304566,
		   chrX  => 155270560,
		   chrY  => 59373566,
		   chrM  => 16571,
		   );



# Pseudoautosomal regions
    my %par = ('hg18' => {chrX => {'five_prime'  => [1, 2709520],
				   'three_prime' => [154584238, 154913754]
				   },
				       chrY => {'five_prime'  => [1, 2709520],
				   'three_prime' => [57443438,  57772954]
				   },
			       },
	       'hg19' => {chrX => {'five_prime'  => [60001, 2699520],
				   'three_prime' => [154931044, 155260560],
			       },
			  chrY => {'five_prime'  => [10001, 2649520],
				   'three_prime' => [59034050,  59363566],
			       }
		      },
	       );
